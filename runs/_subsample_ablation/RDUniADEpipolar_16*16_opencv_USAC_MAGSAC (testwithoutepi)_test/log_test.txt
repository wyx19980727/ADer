2025-09-16 20:30:20,710 - ==> Logging on master GPU: 0
2025-09-16 20:30:20,711 - ==> Running Trainer: RDEpipolarTrainer
2025-09-16 20:30:20,711 - ==> Using GPU: [0] for Training
2025-09-16 20:30:20,711 - ==> Building model
2025-09-16 20:30:20,893 - Loading pretrained weights from url (https://download.pytorch.org/models/resnet18-5c106cde.pth)
2025-09-16 20:30:21,237 - ==> Load checkpoint: runs/_subsample_ablation/RDUniADEpipolar_16*16_opencv_USAC_MAGSAC (testwithoutepi)_train/net.pth
2025-09-16 20:30:21,702 - 
------------------------------------ RDEpipolar ------------------------------------
| module                                             | #parameters or shape   | #flops       |
|:---------------------------------------------------|:-----------------------|:-------------|
| model                                              | 20.811M                | 4.939G       |
|  net_t                                             |  2.783M                |  1.838G      |
|   net_t.conv1                                      |   9.408K               |   0.154G     |
|    net_t.conv1.weight                              |    (64, 3, 7, 7)       |              |
|   net_t.bn1                                        |   0.128K               |   2.097M     |
|    net_t.bn1.weight                                |    (64,)               |              |
|    net_t.bn1.bias                                  |    (64,)               |              |
|   net_t.layer1                                     |   0.148M               |   0.606G     |
|    net_t.layer1.0                                  |    73.984K             |    0.303G    |
|     net_t.layer1.0.conv1                           |     36.864K            |     0.151G   |
|      net_t.layer1.0.conv1.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.0.bn1                             |     0.128K             |     0.524M   |
|      net_t.layer1.0.bn1.weight                     |      (64,)             |              |
|      net_t.layer1.0.bn1.bias                       |      (64,)             |              |
|     net_t.layer1.0.conv2                           |     36.864K            |     0.151G   |
|      net_t.layer1.0.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.0.bn2                             |     0.128K             |     0.524M   |
|      net_t.layer1.0.bn2.weight                     |      (64,)             |              |
|      net_t.layer1.0.bn2.bias                       |      (64,)             |              |
|    net_t.layer1.1                                  |    73.984K             |    0.303G    |
|     net_t.layer1.1.conv1                           |     36.864K            |     0.151G   |
|      net_t.layer1.1.conv1.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.1.bn1                             |     0.128K             |     0.524M   |
|      net_t.layer1.1.bn1.weight                     |      (64,)             |              |
|      net_t.layer1.1.bn1.bias                       |      (64,)             |              |
|     net_t.layer1.1.conv2                           |     36.864K            |     0.151G   |
|      net_t.layer1.1.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.1.bn2                             |     0.128K             |     0.524M   |
|      net_t.layer1.1.bn2.weight                     |      (64,)             |              |
|      net_t.layer1.1.bn2.bias                       |      (64,)             |              |
|   net_t.layer2                                     |   0.526M               |   0.538G     |
|    net_t.layer2.0                                  |    0.23M               |    0.236G    |
|     net_t.layer2.0.conv1                           |     73.728K            |     75.497M  |
|      net_t.layer2.0.conv1.weight                   |      (128, 64, 3, 3)   |              |
|     net_t.layer2.0.bn1                             |     0.256K             |     0.262M   |
|      net_t.layer2.0.bn1.weight                     |      (128,)            |              |
|      net_t.layer2.0.bn1.bias                       |      (128,)            |              |
|     net_t.layer2.0.conv2                           |     0.147M             |     0.151G   |
|      net_t.layer2.0.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_t.layer2.0.bn2                             |     0.256K             |     0.262M   |
|      net_t.layer2.0.bn2.weight                     |      (128,)            |              |
|      net_t.layer2.0.bn2.bias                       |      (128,)            |              |
|     net_t.layer2.0.downsample                      |     8.448K             |     8.651M   |
|      net_t.layer2.0.downsample.0                   |      8.192K            |      8.389M  |
|      net_t.layer2.0.downsample.1                   |      0.256K            |      0.262M  |
|    net_t.layer2.1                                  |    0.295M              |    0.303G    |
|     net_t.layer2.1.conv1                           |     0.147M             |     0.151G   |
|      net_t.layer2.1.conv1.weight                   |      (128, 128, 3, 3)  |              |
|     net_t.layer2.1.bn1                             |     0.256K             |     0.262M   |
|      net_t.layer2.1.bn1.weight                     |      (128,)            |              |
|      net_t.layer2.1.bn1.bias                       |      (128,)            |              |
|     net_t.layer2.1.conv2                           |     0.147M             |     0.151G   |
|      net_t.layer2.1.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_t.layer2.1.bn2                             |     0.256K             |     0.262M   |
|      net_t.layer2.1.bn2.weight                     |      (128,)            |              |
|      net_t.layer2.1.bn2.bias                       |      (128,)            |              |
|   net_t.layer3                                     |   2.1M                 |   0.538G     |
|    net_t.layer3.0                                  |    0.919M              |    0.235G    |
|     net_t.layer3.0.conv1                           |     0.295M             |     75.497M  |
|      net_t.layer3.0.conv1.weight                   |      (256, 128, 3, 3)  |              |
|     net_t.layer3.0.bn1                             |     0.512K             |     0.131M   |
|      net_t.layer3.0.bn1.weight                     |      (256,)            |              |
|      net_t.layer3.0.bn1.bias                       |      (256,)            |              |
|     net_t.layer3.0.conv2                           |     0.59M              |     0.151G   |
|      net_t.layer3.0.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_t.layer3.0.bn2                             |     0.512K             |     0.131M   |
|      net_t.layer3.0.bn2.weight                     |      (256,)            |              |
|      net_t.layer3.0.bn2.bias                       |      (256,)            |              |
|     net_t.layer3.0.downsample                      |     33.28K             |     8.52M    |
|      net_t.layer3.0.downsample.0                   |      32.768K           |      8.389M  |
|      net_t.layer3.0.downsample.1                   |      0.512K            |      0.131M  |
|    net_t.layer3.1                                  |    1.181M              |    0.302G    |
|     net_t.layer3.1.conv1                           |     0.59M              |     0.151G   |
|      net_t.layer3.1.conv1.weight                   |      (256, 256, 3, 3)  |              |
|     net_t.layer3.1.bn1                             |     0.512K             |     0.131M   |
|      net_t.layer3.1.bn1.weight                     |      (256,)            |              |
|      net_t.layer3.1.bn1.bias                       |      (256,)            |              |
|     net_t.layer3.1.conv2                           |     0.59M              |     0.151G   |
|      net_t.layer3.1.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_t.layer3.1.bn2                             |     0.512K             |     0.131M   |
|      net_t.layer3.1.bn2.weight                     |      (256,)            |              |
|      net_t.layer3.1.bn2.bias                       |      (256,)            |              |
|  mff_oce                                           |  5.584M                |  1.486G      |
|   mff_oce.bn_layer                                 |   4.919M               |   1.259G     |
|    mff_oce.bn_layer.0                              |    2.557M              |    0.655G    |
|     mff_oce.bn_layer.0.conv1                       |     1.769M             |     0.453G   |
|      mff_oce.bn_layer.0.conv1.weight               |      (256, 768, 3, 3)  |              |
|     mff_oce.bn_layer.0.bn1                         |     0.512K             |     0.131M   |
|      mff_oce.bn_layer.0.bn1.weight                 |      (256,)            |              |
|      mff_oce.bn_layer.0.bn1.bias                   |      (256,)            |              |
|     mff_oce.bn_layer.0.conv2                       |     0.59M              |     0.151G   |
|      mff_oce.bn_layer.0.conv2.weight               |      (256, 256, 3, 3)  |              |
|     mff_oce.bn_layer.0.bn2                         |     0.512K             |     0.131M   |
|      mff_oce.bn_layer.0.bn2.weight                 |      (256,)            |              |
|      mff_oce.bn_layer.0.bn2.bias                   |      (256,)            |              |
|     mff_oce.bn_layer.0.downsample                  |     0.197M             |     50.463M  |
|      mff_oce.bn_layer.0.downsample.0               |      0.197M            |      50.332M |
|      mff_oce.bn_layer.0.downsample.1               |      0.512K            |      0.131M  |
|    mff_oce.bn_layer.1                              |    1.181M              |    0.302G    |
|     mff_oce.bn_layer.1.conv1                       |     0.59M              |     0.151G   |
|      mff_oce.bn_layer.1.conv1.weight               |      (256, 256, 3, 3)  |              |
|     mff_oce.bn_layer.1.bn1                         |     0.512K             |     0.131M   |
|      mff_oce.bn_layer.1.bn1.weight                 |      (256,)            |              |
|      mff_oce.bn_layer.1.bn1.bias                   |      (256,)            |              |
|     mff_oce.bn_layer.1.conv2                       |     0.59M              |     0.151G   |
|      mff_oce.bn_layer.1.conv2.weight               |      (256, 256, 3, 3)  |              |
|     mff_oce.bn_layer.1.bn2                         |     0.512K             |     0.131M   |
|      mff_oce.bn_layer.1.bn2.weight                 |      (256,)            |              |
|      mff_oce.bn_layer.1.bn2.bias                   |      (256,)            |              |
|    mff_oce.bn_layer.2                              |    1.181M              |    0.302G    |
|     mff_oce.bn_layer.2.conv1                       |     0.59M              |     0.151G   |
|      mff_oce.bn_layer.2.conv1.weight               |      (256, 256, 3, 3)  |              |
|     mff_oce.bn_layer.2.bn1                         |     0.512K             |     0.131M   |
|      mff_oce.bn_layer.2.bn1.weight                 |      (256,)            |              |
|      mff_oce.bn_layer.2.bn1.bias                   |      (256,)            |              |
|     mff_oce.bn_layer.2.conv2                       |     0.59M              |     0.151G   |
|      mff_oce.bn_layer.2.conv2.weight               |      (256, 256, 3, 3)  |              |
|     mff_oce.bn_layer.2.bn2                         |     0.512K             |     0.131M   |
|      mff_oce.bn_layer.2.bn2.weight                 |      (256,)            |              |
|      mff_oce.bn_layer.2.bn2.bias                   |      (256,)            |              |
|   mff_oce.conv1                                    |   73.728K              |   75.497M    |
|    mff_oce.conv1.weight                            |    (128, 64, 3, 3)     |              |
|   mff_oce.bn1                                      |   0.256K               |   0.262M     |
|    mff_oce.bn1.weight                              |    (128,)              |              |
|    mff_oce.bn1.bias                                |    (128,)              |              |
|   mff_oce.conv2                                    |   0.295M               |   75.497M    |
|    mff_oce.conv2.weight                            |    (256, 128, 3, 3)    |              |
|   mff_oce.bn2                                      |   0.512K               |   0.131M     |
|    mff_oce.bn2.weight                              |    (256,)              |              |
|    mff_oce.bn2.bias                                |    (256,)              |              |
|   mff_oce.conv3                                    |   0.295M               |   75.497M    |
|    mff_oce.conv3.weight                            |    (256, 128, 3, 3)    |              |
|   mff_oce.bn3                                      |   0.512K               |   0.131M     |
|    mff_oce.bn3.weight                              |    (256,)              |              |
|    mff_oce.bn3.bias                                |    (256,)              |              |
|  net_s                                             |  3.703M                |  1.044G      |
|   net_s.layer1                                     |   2.821M               |              |
|    net_s.layer1.0                                  |    1.64M               |              |
|     net_s.layer1.0.conv1                           |     0.524M             |              |
|      net_s.layer1.0.conv1.weight                   |      (512, 256, 2, 2)  |              |
|     net_s.layer1.0.bn1                             |     0.512K             |              |
|      net_s.layer1.0.bn1.weight                     |      (256,)            |              |
|      net_s.layer1.0.bn1.bias                       |      (256,)            |              |
|     net_s.layer1.0.conv2                           |     0.59M              |              |
|      net_s.layer1.0.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_s.layer1.0.bn2                             |     0.512K             |              |
|      net_s.layer1.0.bn2.weight                     |      (256,)            |              |
|      net_s.layer1.0.bn2.bias                       |      (256,)            |              |
|     net_s.layer1.0.upsample                        |     0.525M             |              |
|      net_s.layer1.0.upsample.0                     |      0.524M            |              |
|      net_s.layer1.0.upsample.1                     |      0.512K            |              |
|    net_s.layer1.1                                  |    1.181M              |              |
|     net_s.layer1.1.conv1                           |     0.59M              |              |
|      net_s.layer1.1.conv1.weight                   |      (256, 256, 3, 3)  |              |
|     net_s.layer1.1.bn1                             |     0.512K             |              |
|      net_s.layer1.1.bn1.weight                     |      (256,)            |              |
|      net_s.layer1.1.bn1.bias                       |      (256,)            |              |
|     net_s.layer1.1.conv2                           |     0.59M              |              |
|      net_s.layer1.1.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_s.layer1.1.bn2                             |     0.512K             |              |
|      net_s.layer1.1.bn2.weight                     |      (256,)            |              |
|      net_s.layer1.1.bn2.bias                       |      (256,)            |              |
|   net_s.layer2                                     |   0.706M               |   0.521G     |
|    net_s.layer2.0                                  |    0.41M               |    0.219G    |
|     net_s.layer2.0.conv1                           |     0.131M             |     33.554M  |
|      net_s.layer2.0.conv1.weight                   |      (256, 128, 2, 2)  |              |
|     net_s.layer2.0.bn1                             |     0.256K             |     0.262M   |
|      net_s.layer2.0.bn1.weight                     |      (128,)            |              |
|      net_s.layer2.0.bn1.bias                       |      (128,)            |              |
|     net_s.layer2.0.conv2                           |     0.147M             |     0.151G   |
|      net_s.layer2.0.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_s.layer2.0.bn2                             |     0.256K             |     0.262M   |
|      net_s.layer2.0.bn2.weight                     |      (128,)            |              |
|      net_s.layer2.0.bn2.bias                       |      (128,)            |              |
|     net_s.layer2.0.upsample                        |     0.131M             |     33.817M  |
|      net_s.layer2.0.upsample.0                     |      0.131M            |      33.554M |
|      net_s.layer2.0.upsample.1                     |      0.256K            |      0.262M  |
|    net_s.layer2.1                                  |    0.295M              |    0.303G    |
|     net_s.layer2.1.conv1                           |     0.147M             |     0.151G   |
|      net_s.layer2.1.conv1.weight                   |      (128, 128, 3, 3)  |              |
|     net_s.layer2.1.bn1                             |     0.256K             |     0.262M   |
|      net_s.layer2.1.bn1.weight                     |      (128,)            |              |
|      net_s.layer2.1.bn1.bias                       |      (128,)            |              |
|     net_s.layer2.1.conv2                           |     0.147M             |     0.151G   |
|      net_s.layer2.1.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_s.layer2.1.bn2                             |     0.256K             |     0.262M   |
|      net_s.layer2.1.bn2.weight                     |      (128,)            |              |
|      net_s.layer2.1.bn2.bias                       |      (128,)            |              |
|   net_s.layer3                                     |   0.177M               |   0.523G     |
|    net_s.layer3.0                                  |    0.103M              |    0.22G     |
|     net_s.layer3.0.conv1                           |     32.768K            |     33.554M  |
|      net_s.layer3.0.conv1.weight                   |      (128, 64, 2, 2)   |              |
|     net_s.layer3.0.bn1                             |     0.128K             |     0.524M   |
|      net_s.layer3.0.bn1.weight                     |      (64,)             |              |
|      net_s.layer3.0.bn1.bias                       |      (64,)             |              |
|     net_s.layer3.0.conv2                           |     36.864K            |     0.151G   |
|      net_s.layer3.0.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_s.layer3.0.bn2                             |     0.128K             |     0.524M   |
|      net_s.layer3.0.bn2.weight                     |      (64,)             |              |
|      net_s.layer3.0.bn2.bias                       |      (64,)             |              |
|     net_s.layer3.0.upsample                        |     32.896K            |     34.079M  |
|      net_s.layer3.0.upsample.0                     |      32.768K           |      33.554M |
|      net_s.layer3.0.upsample.1                     |      0.128K            |      0.524M  |
|    net_s.layer3.1                                  |    73.984K             |    0.303G    |
|     net_s.layer3.1.conv1                           |     36.864K            |     0.151G   |
|      net_s.layer3.1.conv1.weight                   |      (64, 64, 3, 3)    |              |
|     net_s.layer3.1.bn1                             |     0.128K             |     0.524M   |
|      net_s.layer3.1.bn1.weight                     |      (64,)             |              |
|      net_s.layer3.1.bn1.bias                       |      (64,)             |              |
|     net_s.layer3.1.conv2                           |     36.864K            |     0.151G   |
|      net_s.layer3.1.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_s.layer3.1.bn2                             |     0.128K             |     0.524M   |
|      net_s.layer3.1.bn2.weight                     |      (64,)             |              |
|      net_s.layer3.1.bn2.bias                       |      (64,)             |              |
|  proj_layer                                        |  0.969M                |  0.57G       |
|   proj_layer.proj_a.proj                           |   46.224K              |   0.191G     |
|    proj_layer.proj_a.proj.0                        |    18.464K             |    75.497M   |
|     proj_layer.proj_a.proj.0.weight                |     (32, 64, 3, 3)     |              |
|     proj_layer.proj_a.proj.0.bias                  |     (32,)              |              |
|    proj_layer.proj_a.proj.3                        |    4.624K              |    18.874M   |
|     proj_layer.proj_a.proj.3.weight                |     (16, 32, 3, 3)     |              |
|     proj_layer.proj_a.proj.3.bias                  |     (16,)              |              |
|    proj_layer.proj_a.proj.6                        |    4.64K               |    18.874M   |
|     proj_layer.proj_a.proj.6.weight                |     (32, 16, 3, 3)     |              |
|     proj_layer.proj_a.proj.6.bias                  |     (32,)              |              |
|    proj_layer.proj_a.proj.9                        |    18.496K             |    75.497M   |
|     proj_layer.proj_a.proj.9.weight                |     (64, 32, 3, 3)     |              |
|     proj_layer.proj_a.proj.9.bias                  |     (64,)              |              |
|    proj_layer.proj_a.proj.1                        |                        |    0.524M    |
|    proj_layer.proj_a.proj.4                        |                        |    0.262M    |
|    proj_layer.proj_a.proj.7                        |                        |    0.524M    |
|    proj_layer.proj_a.proj.10                       |                        |    1.049M    |
|   proj_layer.proj_b.proj                           |   0.185M               |   0.19G      |
|    proj_layer.proj_b.proj.0                        |    73.792K             |    75.497M   |
|     proj_layer.proj_b.proj.0.weight                |     (64, 128, 3, 3)    |              |
|     proj_layer.proj_b.proj.0.bias                  |     (64,)              |              |
|    proj_layer.proj_b.proj.3                        |    18.464K             |    18.874M   |
|     proj_layer.proj_b.proj.3.weight                |     (32, 64, 3, 3)     |              |
|     proj_layer.proj_b.proj.3.bias                  |     (32,)              |              |
|    proj_layer.proj_b.proj.6                        |    18.496K             |    18.874M   |
|     proj_layer.proj_b.proj.6.weight                |     (64, 32, 3, 3)     |              |
|     proj_layer.proj_b.proj.6.bias                  |     (64,)              |              |
|    proj_layer.proj_b.proj.9                        |    73.856K             |    75.497M   |
|     proj_layer.proj_b.proj.9.weight                |     (128, 64, 3, 3)    |              |
|     proj_layer.proj_b.proj.9.bias                  |     (128,)             |              |
|    proj_layer.proj_b.proj.1                        |                        |    0.262M    |
|    proj_layer.proj_b.proj.4                        |                        |    0.131M    |
|    proj_layer.proj_b.proj.7                        |                        |    0.262M    |
|    proj_layer.proj_b.proj.10                       |                        |    0.524M    |
|   proj_layer.proj_c.proj                           |   0.738M               |   0.189G     |
|    proj_layer.proj_c.proj.0                        |    0.295M              |    75.497M   |
|     proj_layer.proj_c.proj.0.weight                |     (128, 256, 3, 3)   |              |
|     proj_layer.proj_c.proj.0.bias                  |     (128,)             |              |
|    proj_layer.proj_c.proj.3                        |    73.792K             |    18.874M   |
|     proj_layer.proj_c.proj.3.weight                |     (64, 128, 3, 3)    |              |
|     proj_layer.proj_c.proj.3.bias                  |     (64,)              |              |
|    proj_layer.proj_c.proj.6                        |    73.856K             |    18.874M   |
|     proj_layer.proj_c.proj.6.weight                |     (128, 64, 3, 3)    |              |
|     proj_layer.proj_c.proj.6.bias                  |     (128,)             |              |
|    proj_layer.proj_c.proj.9                        |    0.295M              |    75.497M   |
|     proj_layer.proj_c.proj.9.weight                |     (256, 128, 3, 3)   |              |
|     proj_layer.proj_c.proj.9.bias                  |     (256,)             |              |
|    proj_layer.proj_c.proj.1                        |                        |    0.131M    |
|    proj_layer.proj_c.proj.4                        |                        |    65.536K   |
|    proj_layer.proj_c.proj.7                        |                        |    0.131M    |
|    proj_layer.proj_c.proj.10                       |                        |    0.262M    |
|  net_ad                                            |  7.773M                |              |
|   net_ad.pos_embed                                 |   4.096K               |              |
|    net_ad.pos_embed.row_embed                      |    2.048K              |              |
|     net_ad.pos_embed.row_embed.weight              |     (16, 128)          |              |
|    net_ad.pos_embed.col_embed                      |    2.048K              |              |
|     net_ad.pos_embed.col_embed.weight              |     (16, 128)          |              |
|   net_ad.transformer                               |   7.638M               |              |
|    net_ad.transformer.encoder.layers               |    3.161M              |              |
|     net_ad.transformer.encoder.layers.0            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.0.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.0.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.0.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.0.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.0.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.0.norm_mid  |      0.512K            |              |
|     net_ad.transformer.encoder.layers.1            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.1.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.1.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.1.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.1.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.1.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.1.norm_mid  |      0.512K            |              |
|     net_ad.transformer.encoder.layers.2            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.2.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.2.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.2.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.2.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.2.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.2.norm_mid  |      0.512K            |              |
|     net_ad.transformer.encoder.layers.3            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.3.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.3.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.3.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.3.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.3.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.3.norm_mid  |      0.512K            |              |
|    net_ad.transformer.decoder                      |    4.476M              |              |
|     net_ad.transformer.decoder.layers              |     4.476M             |              |
|      net_ad.transformer.decoder.layers.0           |      1.119M            |              |
|      net_ad.transformer.decoder.layers.1           |      1.119M            |              |
|      net_ad.transformer.decoder.layers.2           |      1.119M            |              |
|      net_ad.transformer.decoder.layers.3           |      1.119M            |              |
|     net_ad.transformer.decoder.norm                |     0.512K             |              |
|      net_ad.transformer.decoder.norm.weight        |      (256,)            |              |
|      net_ad.transformer.decoder.norm.bias          |      (256,)            |              |
|   net_ad.input_proj                                |   65.792K              |              |
|    net_ad.input_proj.weight                        |    (256, 256)          |              |
|    net_ad.input_proj.bias                          |    (256,)              |              |
|   net_ad.output_proj                               |   65.792K              |              |
|    net_ad.output_proj.weight                       |    (256, 256)          |              |
|    net_ad.output_proj.bias                         |    (256,)              |              |
------------------------------------------------------------------------------------
2025-09-16 20:30:21,702 - ==> Creating optimizer
2025-09-16 20:30:21,704 - ==> Loading dataset: RealIAD
2025-09-16 20:30:21,731 - ==> ********** cfg ********** 
fvcore_is                            : True                                
fvcore_b                             : 1                                   
fvcore_c                             : 3                                   
epoch_full                           : 100                                 
metrics                              : ['S_AUROC', 'S_AUPR', 'mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mAUPRO_px', 'mIoU_max_px']
use_adeval                           : True                                
evaluator.kwargs                     : {'metrics': ['S_AUROC', 'S_AUPR', 'mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mAUPRO_px', 'mIoU_max_px'], 'pooling_ks': [16, 16], 'max_step_aupro': 100, 'use_adeval': True}
optim.lr                             : 5e-05                               
optim.kwargs                         : {'name': 'adamw', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
trainer.name                         : RDEpipolarTrainer                   
trainer.checkpoint                   : runs                                
trainer.logdir_sub                   :                                     
trainer.resume_dir                   :                                     
trainer.cuda_deterministic           : False                               
trainer.epoch_full                   : 100                                 
trainer.scheduler_kwargs             : {'name': 'step', 'lr_noise': None, 'noise_pct': 0.67, 'noise_std': 1.0, 'noise_seed': 42, 'lr_min': 5e-07, 'warmup_lr': 5.0000000000000004e-08, 'warmup_iters': -1, 'cooldown_iters': 0, 'warmup_epochs': 0, 'cooldown_epochs': 0, 'use_iters': True, 'patience_iters': 0, 'patience_epochs': 0, 'decay_iters': 0, 'decay_epochs': 80, 'cycle_decay': 0.1, 'decay_rate': 0.1}
trainer.mixup_kwargs                 : {'mixup_alpha': 0.8, 'cutmix_alpha': 1.0, 'cutmix_minmax': None, 'prob': 0.0, 'switch_prob': 0.5, 'mode': 'batch', 'correct_lam': True, 'label_smoothing': 0.1}
trainer.test_start_epoch             : 100                                 
trainer.test_per_epoch               : 100                                 
trainer.find_unused_parameters       : False                               
trainer.sync_BN                      : apex                                
trainer.dist_BN                      :                                     
trainer.scaler                       : native                              
trainer.data.batch_size              : 4                                   
trainer.data.batch_size_per_gpu      : 4                                   
trainer.data.batch_size_test         : 4                                   
trainer.data.batch_size_per_gpu_test : 4                                   
trainer.data.num_workers_per_gpu     : 8                                   
trainer.data.drop_last               : True                                
trainer.data.pin_memory              : True                                
trainer.data.persistent_workers      : False                               
trainer.data.num_workers             : 8                                   
trainer.iter                         : 0                                   
trainer.epoch                        : 0                                   
trainer.iter_full                    : 17900                               
trainer.metric_recorder              : {'S_AUROC_audiojack': [], 'S_AUPR_audiojack': [], 'mAUROC_sp_max_audiojack': [], 'mAP_sp_max_audiojack': [], 'mF1_max_sp_max_audiojack': [], 'mAUROC_px_audiojack': [], 'mAP_px_audiojack': [], 'mF1_max_px_audiojack': [], 'mAUPRO_px_audiojack': [], 'mIoU_max_px_audiojack': [], 'S_AUROC_bottle_cap': [], 'S_AUPR_bottle_cap': [], 'mAUROC_sp_max_bottle_cap': [], 'mAP_sp_max_bottle_cap': [], 'mF1_max_sp_max_bottle_cap': [], 'mAUROC_px_bottle_cap': [], 'mAP_px_bottle_cap': [], 'mF1_max_px_bottle_cap': [], 'mAUPRO_px_bottle_cap': [], 'mIoU_max_px_bottle_cap': [], 'S_AUROC_button_battery': [], 'S_AUPR_button_battery': [], 'mAUROC_sp_max_button_battery': [], 'mAP_sp_max_button_battery': [], 'mF1_max_sp_max_button_battery': [], 'mAUROC_px_button_battery': [], 'mAP_px_button_battery': [], 'mF1_max_px_button_battery': [], 'mAUPRO_px_button_battery': [], 'mIoU_max_px_button_battery': [], 'S_AUROC_end_cap': [], 'S_AUPR_end_cap': [], 'mAUROC_sp_max_end_cap': [], 'mAP_sp_max_end_cap': [], 'mF1_max_sp_max_end_cap': [], 'mAUROC_px_end_cap': [], 'mAP_px_end_cap': [], 'mF1_max_px_end_cap': [], 'mAUPRO_px_end_cap': [], 'mIoU_max_px_end_cap': [], 'S_AUROC_eraser': [], 'S_AUPR_eraser': [], 'mAUROC_sp_max_eraser': [], 'mAP_sp_max_eraser': [], 'mF1_max_sp_max_eraser': [], 'mAUROC_px_eraser': [], 'mAP_px_eraser': [], 'mF1_max_px_eraser': [], 'mAUPRO_px_eraser': [], 'mIoU_max_px_eraser': [], 'S_AUROC_fire_hood': [], 'S_AUPR_fire_hood': [], 'mAUROC_sp_max_fire_hood': [], 'mAP_sp_max_fire_hood': [], 'mF1_max_sp_max_fire_hood': [], 'mAUROC_px_fire_hood': [], 'mAP_px_fire_hood': [], 'mF1_max_px_fire_hood': [], 'mAUPRO_px_fire_hood': [], 'mIoU_max_px_fire_hood': [], 'S_AUROC_mint': [], 'S_AUPR_mint': [], 'mAUROC_sp_max_mint': [], 'mAP_sp_max_mint': [], 'mF1_max_sp_max_mint': [], 'mAUROC_px_mint': [], 'mAP_px_mint': [], 'mF1_max_px_mint': [], 'mAUPRO_px_mint': [], 'mIoU_max_px_mint': [], 'S_AUROC_mounts': [], 'S_AUPR_mounts': [], 'mAUROC_sp_max_mounts': [], 'mAP_sp_max_mounts': [], 'mF1_max_sp_max_mounts': [], 'mAUROC_px_mounts': [], 'mAP_px_mounts': [], 'mF1_max_px_mounts': [], 'mAUPRO_px_mounts': [], 'mIoU_max_px_mounts': [], 'S_AUROC_pcb': [], 'S_AUPR_pcb': [], 'mAUROC_sp_max_pcb': [], 'mAP_sp_max_pcb': [], 'mF1_max_sp_max_pcb': [], 'mAUROC_px_pcb': [], 'mAP_px_pcb': [], 'mF1_max_px_pcb': [], 'mAUPRO_px_pcb': [], 'mIoU_max_px_pcb': [], 'S_AUROC_phone_battery': [], 'S_AUPR_phone_battery': [], 'mAUROC_sp_max_phone_battery': [], 'mAP_sp_max_phone_battery': [], 'mF1_max_sp_max_phone_battery': [], 'mAUROC_px_phone_battery': [], 'mAP_px_phone_battery': [], 'mF1_max_px_phone_battery': [], 'mAUPRO_px_phone_battery': [], 'mIoU_max_px_phone_battery': [], 'S_AUROC_plastic_nut': [], 'S_AUPR_plastic_nut': [], 'mAUROC_sp_max_plastic_nut': [], 'mAP_sp_max_plastic_nut': [], 'mF1_max_sp_max_plastic_nut': [], 'mAUROC_px_plastic_nut': [], 'mAP_px_plastic_nut': [], 'mF1_max_px_plastic_nut': [], 'mAUPRO_px_plastic_nut': [], 'mIoU_max_px_plastic_nut': [], 'S_AUROC_plastic_plug': [], 'S_AUPR_plastic_plug': [], 'mAUROC_sp_max_plastic_plug': [], 'mAP_sp_max_plastic_plug': [], 'mF1_max_sp_max_plastic_plug': [], 'mAUROC_px_plastic_plug': [], 'mAP_px_plastic_plug': [], 'mF1_max_px_plastic_plug': [], 'mAUPRO_px_plastic_plug': [], 'mIoU_max_px_plastic_plug': [], 'S_AUROC_porcelain_doll': [], 'S_AUPR_porcelain_doll': [], 'mAUROC_sp_max_porcelain_doll': [], 'mAP_sp_max_porcelain_doll': [], 'mF1_max_sp_max_porcelain_doll': [], 'mAUROC_px_porcelain_doll': [], 'mAP_px_porcelain_doll': [], 'mF1_max_px_porcelain_doll': [], 'mAUPRO_px_porcelain_doll': [], 'mIoU_max_px_porcelain_doll': [], 'S_AUROC_regulator': [], 'S_AUPR_regulator': [], 'mAUROC_sp_max_regulator': [], 'mAP_sp_max_regulator': [], 'mF1_max_sp_max_regulator': [], 'mAUROC_px_regulator': [], 'mAP_px_regulator': [], 'mF1_max_px_regulator': [], 'mAUPRO_px_regulator': [], 'mIoU_max_px_regulator': [], 'S_AUROC_rolled_strip_base': [], 'S_AUPR_rolled_strip_base': [], 'mAUROC_sp_max_rolled_strip_base': [], 'mAP_sp_max_rolled_strip_base': [], 'mF1_max_sp_max_rolled_strip_base': [], 'mAUROC_px_rolled_strip_base': [], 'mAP_px_rolled_strip_base': [], 'mF1_max_px_rolled_strip_base': [], 'mAUPRO_px_rolled_strip_base': [], 'mIoU_max_px_rolled_strip_base': [], 'S_AUROC_sim_card_set': [], 'S_AUPR_sim_card_set': [], 'mAUROC_sp_max_sim_card_set': [], 'mAP_sp_max_sim_card_set': [], 'mF1_max_sp_max_sim_card_set': [], 'mAUROC_px_sim_card_set': [], 'mAP_px_sim_card_set': [], 'mF1_max_px_sim_card_set': [], 'mAUPRO_px_sim_card_set': [], 'mIoU_max_px_sim_card_set': [], 'S_AUROC_switch': [], 'S_AUPR_switch': [], 'mAUROC_sp_max_switch': [], 'mAP_sp_max_switch': [], 'mF1_max_sp_max_switch': [], 'mAUROC_px_switch': [], 'mAP_px_switch': [], 'mF1_max_px_switch': [], 'mAUPRO_px_switch': [], 'mIoU_max_px_switch': [], 'S_AUROC_tape': [], 'S_AUPR_tape': [], 'mAUROC_sp_max_tape': [], 'mAP_sp_max_tape': [], 'mF1_max_sp_max_tape': [], 'mAUROC_px_tape': [], 'mAP_px_tape': [], 'mF1_max_px_tape': [], 'mAUPRO_px_tape': [], 'mIoU_max_px_tape': [], 'S_AUROC_terminalblock': [], 'S_AUPR_terminalblock': [], 'mAUROC_sp_max_terminalblock': [], 'mAP_sp_max_terminalblock': [], 'mF1_max_sp_max_terminalblock': [], 'mAUROC_px_terminalblock': [], 'mAP_px_terminalblock': [], 'mF1_max_px_terminalblock': [], 'mAUPRO_px_terminalblock': [], 'mIoU_max_px_terminalblock': [], 'S_AUROC_toothbrush': [], 'S_AUPR_toothbrush': [], 'mAUROC_sp_max_toothbrush': [], 'mAP_sp_max_toothbrush': [], 'mF1_max_sp_max_toothbrush': [], 'mAUROC_px_toothbrush': [], 'mAP_px_toothbrush': [], 'mF1_max_px_toothbrush': [], 'mAUPRO_px_toothbrush': [], 'mIoU_max_px_toothbrush': [], 'S_AUROC_toy': [], 'S_AUPR_toy': [], 'mAUROC_sp_max_toy': [], 'mAP_sp_max_toy': [], 'mF1_max_sp_max_toy': [], 'mAUROC_px_toy': [], 'mAP_px_toy': [], 'mF1_max_px_toy': [], 'mAUPRO_px_toy': [], 'mIoU_max_px_toy': [], 'S_AUROC_toy_brick': [], 'S_AUPR_toy_brick': [], 'mAUROC_sp_max_toy_brick': [], 'mAP_sp_max_toy_brick': [], 'mF1_max_sp_max_toy_brick': [], 'mAUROC_px_toy_brick': [], 'mAP_px_toy_brick': [], 'mF1_max_px_toy_brick': [], 'mAUPRO_px_toy_brick': [], 'mIoU_max_px_toy_brick': [], 'S_AUROC_transistor1': [], 'S_AUPR_transistor1': [], 'mAUROC_sp_max_transistor1': [], 'mAP_sp_max_transistor1': [], 'mF1_max_sp_max_transistor1': [], 'mAUROC_px_transistor1': [], 'mAP_px_transistor1': [], 'mF1_max_px_transistor1': [], 'mAUPRO_px_transistor1': [], 'mIoU_max_px_transistor1': [], 'S_AUROC_u_block': [], 'S_AUPR_u_block': [], 'mAUROC_sp_max_u_block': [], 'mAP_sp_max_u_block': [], 'mF1_max_sp_max_u_block': [], 'mAUROC_px_u_block': [], 'mAP_px_u_block': [], 'mF1_max_px_u_block': [], 'mAUPRO_px_u_block': [], 'mIoU_max_px_u_block': [], 'S_AUROC_usb': [], 'S_AUPR_usb': [], 'mAUROC_sp_max_usb': [], 'mAP_sp_max_usb': [], 'mF1_max_sp_max_usb': [], 'mAUROC_px_usb': [], 'mAP_px_usb': [], 'mF1_max_px_usb': [], 'mAUPRO_px_usb': [], 'mIoU_max_px_usb': [], 'S_AUROC_usb_adaptor': [], 'S_AUPR_usb_adaptor': [], 'mAUROC_sp_max_usb_adaptor': [], 'mAP_sp_max_usb_adaptor': [], 'mF1_max_sp_max_usb_adaptor': [], 'mAUROC_px_usb_adaptor': [], 'mAP_px_usb_adaptor': [], 'mF1_max_px_usb_adaptor': [], 'mAUPRO_px_usb_adaptor': [], 'mIoU_max_px_usb_adaptor': [], 'S_AUROC_vcpill': [], 'S_AUPR_vcpill': [], 'mAUROC_sp_max_vcpill': [], 'mAP_sp_max_vcpill': [], 'mF1_max_sp_max_vcpill': [], 'mAUROC_px_vcpill': [], 'mAP_px_vcpill': [], 'mF1_max_px_vcpill': [], 'mAUPRO_px_vcpill': [], 'mIoU_max_px_vcpill': [], 'S_AUROC_wooden_beads': [], 'S_AUPR_wooden_beads': [], 'mAUROC_sp_max_wooden_beads': [], 'mAP_sp_max_wooden_beads': [], 'mF1_max_sp_max_wooden_beads': [], 'mAUROC_px_wooden_beads': [], 'mAP_px_wooden_beads': [], 'mF1_max_px_wooden_beads': [], 'mAUPRO_px_wooden_beads': [], 'mIoU_max_px_wooden_beads': [], 'S_AUROC_woodstick': [], 'S_AUPR_woodstick': [], 'mAUROC_sp_max_woodstick': [], 'mAP_sp_max_woodstick': [], 'mF1_max_sp_max_woodstick': [], 'mAUROC_px_woodstick': [], 'mAP_px_woodstick': [], 'mF1_max_px_woodstick': [], 'mAUPRO_px_woodstick': [], 'mIoU_max_px_woodstick': [], 'S_AUROC_zipper': [], 'S_AUROC_Avg': [], 'S_AUPR_zipper': [], 'S_AUPR_Avg': [], 'mAUROC_sp_max_zipper': [], 'mAUROC_sp_max_Avg': [], 'mAP_sp_max_zipper': [], 'mAP_sp_max_Avg': [], 'mF1_max_sp_max_zipper': [], 'mF1_max_sp_max_Avg': [], 'mAUROC_px_zipper': [], 'mAUROC_px_Avg': [], 'mAP_px_zipper': [], 'mAP_px_Avg': [], 'mF1_max_px_zipper': [], 'mF1_max_px_Avg': [], 'mAUPRO_px_zipper': [], 'mAUPRO_px_Avg': [], 'mIoU_max_px_zipper': [], 'mIoU_max_px_Avg': []}
loss.loss_terms                      : [{'type': 'CosLoss', 'name': 'cos', 'avg': False, 'lam': 1.0}]
loss.clip_grad                       : 5.0                                 
loss.create_graph                    : False                               
loss.retain_graph                    : False                               
adv                                  : False                               
logging.log_terms_train              : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'data_t', 'fmt': ':>5.3f'}, {'name': 'optim_t', 'fmt': ':>5.3f'}, {'name': 'lr', 'fmt': ':>7.6f'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.log_terms_test               : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.train_reset_log_per          : 50                                  
logging.train_log_per                : 50                                  
logging.test_log_per                 : 50                                  
data.sampler                         : naive                               
data.loader_type                     : pil                                 
data.loader_type_target              : pil_L                               
data.type                            : RealIAD                             
data.root                            : /home/albus/DataSets/REAL-IAD/realiad_256
data.meta                            : meta.json                           
data.cls_names                       : []                                  
data.train_transforms                : [{'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.test_transforms                 : [{'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.target_transforms               : [{'type': 'ToTensor'}]              
data.use_sample                      : True                                
data.views                           : []                                  
data.train_size                      : 179                                 
data.test_size                       : 567                                 
data.train_length                    : 717                                 
data.test_length                     : 2266                                
model_t.name                         : timm_resnet18                       
model_t.kwargs                       : {'pretrained': True, 'checkpoint_path': '', 'strict': False, 'features_only': True, 'out_indices': [1, 2, 3]}
model_s.name                         : de_resnet18                         
model_s.kwargs                       : {'pretrained': False, 'checkpoint_path': '', 'strict': False}
model.name                           : rdepipolar                          
model.kwargs                         : {'pretrained': True, 'checkpoint_path': 'runs/_subsample_ablation/RDUniADEpipolar_16*16_opencv_USAC_MAGSAC (testwithoutepi)_train/net.pth', 'strict': True, 'model_t': Namespace(kwargs={'pretrained': True, 'checkpoint_path': '', 'strict': False, 'features_only': True, 'out_indices': [1, 2, 3]}, name='timm_resnet18'), 'model_s': Namespace(kwargs={'pretrained': False, 'checkpoint_path': '', 'strict': False}, name='de_resnet18')}
seed                                 : 42                                  
size                                 : 256                                 
warmup_epochs                        : 0                                   
test_start_epoch                     : 100                                 
test_per_epoch                       : 100                                 
batch_train                          : 4                                   
batch_test_per                       : 4                                   
lr                                   : 5e-05                               
weight_decay                         : 0.0001                              
cfg_path                             : configs.z_realiad_subsample.rdepipolar_256_100e
mode                                 : test                                
sleep                                : -1                                  
memory                               : -1                                  
dist_url                             : env://                              
logger_rank                          : 0                                   
opts                                 : []                                  
command                              : python3 -m torch.distributed.launch --nproc_per_node=$nproc_per_node --nnodes=$nnodes --node_rank=$node_rank --master_addr=$master_addr --master_port=$master_port --use_env run.py -c configs.z_realiad_subsample.rdepipolar_256_100e -m test --sleep -1 --memory -1 --dist_url env:// --logger_rank 0 
task_start_time                      : 3046911.623242924                   
dist                                 : False                               
world_size                           : 1                                   
rank                                 : 0                                   
local_rank                           : 0                                   
ngpus_per_node                       : 1                                   
nnodes                               : 1                                   
master                               : True                                
logdir                               : runs/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250916-203020
logger.filters                       : []                                  
logger.name                          : root                                
logger.level                         : 20                                  
logger.parent                        : None                                
logger.propagate                     : True                                
logger.disabled                      : False                               
logdir_train                         : runs/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250916-203020/show_train
logdir_test                          : runs/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250916-203020/show_test
2025-09-16 20:30:21,731 - ==> Starting testing with 1 nodes x 1 GPUs
2025-09-16 20:30:26,170 - Test: 8.82% [50/567] [batch_t 0.073 (0.086)] [cos 0.388 (0.320)]
2025-09-16 20:30:29,874 - Test: 17.64% [100/567] [batch_t 0.074 (0.080)] [cos 0.244 (0.320)]
2025-09-16 20:30:33,568 - Test: 26.46% [150/567] [batch_t 0.073 (0.078)] [cos 0.325 (0.329)]
2025-09-16 20:30:37,278 - Test: 35.27% [200/567] [batch_t 0.074 (0.077)] [cos 0.477 (0.361)]
2025-09-16 20:30:40,979 - Test: 44.09% [250/567] [batch_t 0.074 (0.076)] [cos 0.452 (0.357)]
2025-09-16 20:30:44,693 - Test: 52.91% [300/567] [batch_t 0.074 (0.076)] [cos 0.508 (0.368)]
2025-09-16 20:30:48,409 - Test: 61.73% [350/567] [batch_t 0.074 (0.076)] [cos 0.383 (0.364)]
2025-09-16 20:30:52,131 - Test: 70.55% [400/567] [batch_t 0.073 (0.076)] [cos 0.432 (0.372)]
2025-09-16 20:30:55,846 - Test: 79.37% [450/567] [batch_t 0.073 (0.075)] [cos 0.259 (0.369)]
2025-09-16 20:30:59,565 - Test: 88.18% [500/567] [batch_t 0.073 (0.075)] [cos 0.233 (0.372)]
2025-09-16 20:31:03,365 - Test: 97.00% [550/567] [batch_t 0.080 (0.075)] [cos 0.377 (0.371)]
2025-09-16 20:31:04,733 - Test: 100.00% [567/567] [batch_t 0.207 (0.076)] [cos 0.499 (0.372)]
2025-09-16 20:31:08,103 - ==> Metric Time for audiojack      :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.002 (mAUROC_sp_max)	  0.001 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.874 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.861 (mIoU_max_px)	
2025-09-16 20:31:11,674 - ==> Metric Time for bottle_cap     :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.972 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.953 (mIoU_max_px)	
2025-09-16 20:31:15,100 - ==> Metric Time for button_battery :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.877 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.880 (mIoU_max_px)	
2025-09-16 20:31:18,476 - ==> Metric Time for end_cap        :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.858 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.841 (mIoU_max_px)	
2025-09-16 20:31:21,829 - ==> Metric Time for eraser         :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.848 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.850 (mIoU_max_px)	
2025-09-16 20:31:25,184 - ==> Metric Time for fire_hood      :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.904 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.831 (mIoU_max_px)	
2025-09-16 20:31:29,231 - ==> Metric Time for mint           :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  1.052 (mF1_max_px)	  0.000 (mAUPRO_px)	  1.014 (mIoU_max_px)	
2025-09-16 20:31:32,498 - ==> Metric Time for mounts         :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.827 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.821 (mIoU_max_px)	
2025-09-16 20:31:35,802 - ==> Metric Time for pcb            :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.825 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.835 (mIoU_max_px)	
2025-09-16 20:31:39,116 - ==> Metric Time for phone_battery  :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.849 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.831 (mIoU_max_px)	
2025-09-16 20:31:42,401 - ==> Metric Time for plastic_nut    :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.831 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.836 (mIoU_max_px)	
2025-09-16 20:31:45,707 - ==> Metric Time for plastic_plug   :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.001 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.843 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.828 (mIoU_max_px)	
2025-09-16 20:31:49,004 - ==> Metric Time for porcelain_doll :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.832 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.844 (mIoU_max_px)	
2025-09-16 20:31:52,305 - ==> Metric Time for regulator      :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.842 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.835 (mIoU_max_px)	
2025-09-16 20:31:55,653 - ==> Metric Time for rolled_strip_base:   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.844 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.830 (mIoU_max_px)	
2025-09-16 20:31:58,930 - ==> Metric Time for sim_card_set   :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.001 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.827 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.830 (mIoU_max_px)	
2025-09-16 20:32:02,323 - ==> Metric Time for switch         :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.001 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.878 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.858 (mIoU_max_px)	
2025-09-16 20:32:05,781 - ==> Metric Time for tape           :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.894 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.899 (mIoU_max_px)	
2025-09-16 20:32:09,213 - ==> Metric Time for terminalblock  :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.846 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.861 (mIoU_max_px)	
2025-09-16 20:32:12,637 - ==> Metric Time for toothbrush     :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.873 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.854 (mIoU_max_px)	
2025-09-16 20:32:15,992 - ==> Metric Time for toy            :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.860 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.864 (mIoU_max_px)	
2025-09-16 20:32:19,316 - ==> Metric Time for toy_brick      :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.864 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.837 (mIoU_max_px)	
2025-09-16 20:32:22,601 - ==> Metric Time for transistor1    :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.822 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.824 (mIoU_max_px)	
2025-09-16 20:32:25,791 - ==> Metric Time for u_block        :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.815 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.802 (mIoU_max_px)	
2025-09-16 20:32:29,100 - ==> Metric Time for usb            :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.846 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.833 (mIoU_max_px)	
2025-09-16 20:32:32,484 - ==> Metric Time for usb_adaptor    :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.848 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.852 (mIoU_max_px)	
2025-09-16 20:32:35,789 - ==> Metric Time for vcpill         :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.851 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.823 (mIoU_max_px)	
2025-09-16 20:32:39,190 - ==> Metric Time for wooden_beads   :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.857 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.864 (mIoU_max_px)	
2025-09-16 20:32:42,513 - ==> Metric Time for woodstick      :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.834 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.840 (mIoU_max_px)	
2025-09-16 20:32:45,848 - ==> Metric Time for zipper         :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.001 (mAUROC_sp_max)	  0.000 (mAP_sp_max)	  0.000 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  0.837 (mF1_max_px)	  0.000 (mAUPRO_px)	  0.829 (mIoU_max_px)	
2025-09-16 20:32:45,861 - 
|       Name        |  S_AUROC  |   S_AUROC (Max)    |  S_AUPR  |    S_AUPR (Max)    |  mAUROC_sp_max  |  mAUROC_sp_max (Max)  |  mAP_sp_max  |  mAP_sp_max (Max)  |  mF1_max_sp_max  |  mF1_max_sp_max (Max)  |  mAUROC_px  |  mAUROC_px (Max)   |  mAP_px  |    mAP_px (Max)    |  mF1_max_px  |  mF1_max_px (Max)  |  mAUPRO_px  |  mAUPRO_px (Max)   |  mIoU_max_px  |  mIoU_max_px (Max)  |
|:-----------------:|:---------:|:------------------:|:--------:|:------------------:|:---------------:|:---------------------:|:------------:|:------------------:|:----------------:|:----------------------:|:-----------:|:------------------:|:--------:|:------------------:|:------------:|:------------------:|:-----------:|:------------------:|:-------------:|:-------------------:|
|     audiojack     |  87.214   | 87.214 (1   epoch) |  94.245  | 94.245 (1   epoch) |     63.927      |  63.927 (1   epoch)   |    48.471    | 48.471 (1   epoch) |      59.485      |   59.485 (1   epoch)   |   94.911    | 94.911 (1   epoch) |  7.647   | 7.647 (1   epoch)  |    15.410    | 15.410 (1   epoch) |   72.892    | 72.892 (1   epoch) |     8.348     |  8.348 (1   epoch)  |
|    bottle_cap     |  76.675   | 76.675 (1   epoch) |  89.956  | 89.956 (1   epoch) |     73.178      |  73.178 (1   epoch)   |    67.522    | 67.522 (1   epoch) |      68.222      |   68.222 (1   epoch)   |   98.722    | 98.722 (1   epoch) |  27.837  | 27.837 (1   epoch) |    35.598    | 35.598 (1   epoch) |   93.902    | 93.902 (1   epoch) |    21.653     | 21.653 (1   epoch)  |
|  button_battery   |  74.224   | 74.224 (1   epoch) |  87.398  | 87.398 (1   epoch) |     67.466      |  67.466 (1   epoch)   |    77.451    | 77.451 (1   epoch) |      78.369      |   78.369 (1   epoch)   |   93.363    | 93.363 (1   epoch) |  27.912  | 27.912 (1   epoch) |    34.042    | 34.042 (1   epoch) |   75.845    | 75.845 (1   epoch) |    20.512     | 20.512 (1   epoch)  |
|      end_cap      |  69.912   | 69.912 (1   epoch) |  80.288  | 80.288 (1   epoch) |     59.436      |  59.436 (1   epoch)   |    65.810    | 65.810 (1   epoch) |      73.435      |   73.435 (1   epoch)   |   84.972    | 84.972 (1   epoch) |  3.626   | 3.626 (1   epoch)  |    9.973     | 9.973 (1   epoch)  |   60.318    | 60.318 (1   epoch) |     5.248     |  5.248 (1   epoch)  |
|      eraser       |  89.744   | 89.744 (1   epoch) |  96.102  | 96.102 (1   epoch) |     85.601      |  85.601 (1   epoch)   |    85.099    | 85.099 (1   epoch) |      76.873      |   76.873 (1   epoch)   |   98.582    | 98.582 (1   epoch) |  26.428  | 26.428 (1   epoch) |    32.169    | 32.169 (1   epoch) |   92.170    | 92.170 (1   epoch) |    19.168     | 19.168 (1   epoch)  |
|     fire_hood     |  81.120   | 81.120 (1   epoch) |  89.921  | 89.921 (1   epoch) |     74.190      |  74.190 (1   epoch)   |    70.137    | 70.137 (1   epoch) |      61.472      |   61.472 (1   epoch)   |   98.007    | 98.007 (1   epoch) |  26.646  | 26.646 (1   epoch) |    34.003    | 34.003 (1   epoch) |   84.258    | 84.258 (1   epoch) |    20.484     | 20.484 (1   epoch)  |
|       mint        |  48.958   | 48.958 (1   epoch) |  80.248  | 80.248 (1   epoch) |     55.287      |  55.287 (1   epoch)   |    51.500    | 51.500 (1   epoch) |      65.116      |   65.116 (1   epoch)   |   92.247    | 92.247 (1   epoch) |  3.110   | 3.110 (1   epoch)  |    7.295     | 7.295 (1   epoch)  |   60.707    | 60.707 (1   epoch) |     3.785     |  3.785 (1   epoch)  |
|      mounts       |  91.953   | 91.953 (1   epoch) |  96.655  | 96.655 (1   epoch) |     76.064      |  76.064 (1   epoch)   |    70.154    | 70.154 (1   epoch) |      61.111      |   61.111 (1   epoch)   |   97.057    | 97.057 (1   epoch) |  27.289  | 27.289 (1   epoch) |    32.791    | 32.791 (1   epoch) |   84.699    | 84.699 (1   epoch) |    19.610     | 19.610 (1   epoch)  |
|        pcb        |  65.792   | 65.792 (1   epoch) |  81.443  | 81.443 (1   epoch) |     59.837      |  59.837 (1   epoch)   |    72.512    | 72.512 (1   epoch) |      75.465      |   75.465 (1   epoch)   |   90.727    | 90.727 (1   epoch) |  1.629   | 1.629 (1   epoch)  |    4.343     | 4.343 (1   epoch)  |   62.386    | 62.386 (1   epoch) |     2.220     |  2.220 (1   epoch)  |
|   phone_battery   |  62.459   | 62.459 (1   epoch) |  83.951  | 83.951 (1   epoch) |     64.048      |  64.048 (1   epoch)   |    65.173    | 65.173 (1   epoch) |      59.658      |   59.658 (1   epoch)   |   94.258    | 94.258 (1   epoch) |  19.373  | 19.373 (1   epoch) |    29.098    | 29.098 (1   epoch) |   79.127    | 79.127 (1   epoch) |    17.026     | 17.026 (1   epoch)  |
|    plastic_nut    |  71.240   | 71.240 (1   epoch) |  84.791  | 84.791 (1   epoch) |     67.594      |  67.594 (1   epoch)   |    49.508    | 49.508 (1   epoch) |      56.230      |   56.230 (1   epoch)   |   96.082    | 96.082 (1   epoch) |  8.417   | 8.417 (1   epoch)  |    17.666    | 17.666 (1   epoch) |   83.364    | 83.364 (1   epoch) |     9.689     |  9.689 (1   epoch)  |
|   plastic_plug    |  76.103   | 76.103 (1   epoch) |  88.982  | 88.982 (1   epoch) |     76.123      |  76.123 (1   epoch)   |    68.822    | 68.822 (1   epoch) |      63.946      |   63.946 (1   epoch)   |   98.104    | 98.104 (1   epoch) |  21.211  | 21.211 (1   epoch) |    31.041    | 31.041 (1   epoch) |   90.509    | 90.509 (1   epoch) |    18.372     | 18.372 (1   epoch)  |
|  porcelain_doll   |  82.190   | 82.190 (1   epoch) |  85.908  | 85.908 (1   epoch) |     69.374      |  69.374 (1   epoch)   |    52.284    | 52.284 (1   epoch) |      56.688      |   56.688 (1   epoch)   |   96.500    | 96.500 (1   epoch) |  6.295   | 6.295 (1   epoch)  |    10.870    | 10.870 (1   epoch) |   86.435    | 86.435 (1   epoch) |     5.747     |  5.747 (1   epoch)  |
|     regulator     |  42.308   | 42.308 (1   epoch) |  62.386  | 62.386 (1   epoch) |     36.543      |  36.543 (1   epoch)   |    19.694    | 19.694 (1   epoch) |      41.438      |   41.438 (1   epoch)   |   83.382    | 83.382 (1   epoch) |  0.104   | 0.104 (1   epoch)  |    0.293     | 0.293 (1   epoch)  |   50.844    | 50.844 (1   epoch) |     0.147     |  0.147 (1   epoch)  |
| rolled_strip_base |  88.194   | 88.194 (1   epoch) |  95.430  | 95.430 (1   epoch) |     79.072      |  79.072 (1   epoch)   |    90.362    | 90.362 (1   epoch) |      82.578      |   82.578 (1   epoch)   |   97.508    | 97.508 (1   epoch) |  17.523  | 17.523 (1   epoch) |    27.507    | 27.507 (1   epoch) |   93.451    | 93.451 (1   epoch) |    15.947     | 15.947 (1   epoch)  |
|   sim_card_set    |  83.917   | 83.917 (1   epoch) |  90.235  | 90.235 (1   epoch) |     82.030      |  82.030 (1   epoch)   |    78.818    | 78.818 (1   epoch) |      79.310      |   79.310 (1   epoch)   |   98.207    | 98.207 (1   epoch) |  27.040  | 27.040 (1   epoch) |    35.456    | 35.456 (1   epoch) |   88.796    | 88.796 (1   epoch) |    21.548     | 21.548 (1   epoch)  |
|      switch       |  71.814   | 71.814 (1   epoch) |  84.553  | 84.553 (1   epoch) |     69.578      |  69.578 (1   epoch)   |    73.833    | 73.833 (1   epoch) |      70.209      |   70.209 (1   epoch)   |   92.321    | 92.321 (1   epoch) |  8.170   | 8.170 (1   epoch)  |    15.005    | 15.005 (1   epoch) |   77.813    | 77.813 (1   epoch) |     8.111     |  8.111 (1   epoch)  |
|       tape        |  94.192   | 94.192 (1   epoch) |  97.470  | 97.470 (1   epoch) |     90.587      |  90.587 (1   epoch)   |    90.202    | 90.202 (1   epoch) |      84.733      |   84.733 (1   epoch)   |   98.913    | 98.913 (1   epoch) |  32.618  | 32.618 (1   epoch) |    39.651    | 39.651 (1   epoch) |   95.827    | 95.827 (1   epoch) |    24.728     | 24.728 (1   epoch)  |
|   terminalblock   |  78.846   | 78.846 (1   epoch) |  90.477  | 90.477 (1   epoch) |     66.888      |  66.888 (1   epoch)   |    73.015    | 73.015 (1   epoch) |      71.795      |   71.795 (1   epoch)   |   96.175    | 96.175 (1   epoch) |  17.626  | 17.626 (1   epoch) |    23.765    | 23.765 (1   epoch) |   86.929    | 86.929 (1   epoch) |    13.485     | 13.485 (1   epoch)  |
|    toothbrush     |  73.938   | 73.938 (1   epoch) |  87.227  | 87.227 (1   epoch) |     68.921      |  68.921 (1   epoch)   |    74.003    | 74.003 (1   epoch) |      74.144      |   74.144 (1   epoch)   |   91.487    | 91.487 (1   epoch) |  9.230   | 9.230 (1   epoch)  |    15.178    | 15.178 (1   epoch) |   73.805    | 73.805 (1   epoch) |     8.212     |  8.212 (1   epoch)  |
|        toy        |  58.042   | 58.042 (1   epoch) |  75.465  | 75.465 (1   epoch) |     51.612      |  51.612 (1   epoch)   |    58.688    | 58.688 (1   epoch) |      73.830      |   73.830 (1   epoch)   |   86.946    | 86.946 (1   epoch) |  0.854   | 0.854 (1   epoch)  |    3.084     | 3.084 (1   epoch)  |   65.405    | 65.405 (1   epoch) |     1.566     |  1.566 (1   epoch)  |
|     toy_brick     |  82.458   | 82.458 (1   epoch) |  87.761  | 87.761 (1   epoch) |     68.895      |  68.895 (1   epoch)   |    60.999    | 60.999 (1   epoch) |      68.558      |   68.558 (1   epoch)   |   96.612    | 96.612 (1   epoch) |  11.351  | 11.351 (1   epoch) |    21.583    | 21.583 (1   epoch) |   81.332    | 81.332 (1   epoch) |    12.097     | 12.097 (1   epoch)  |
|    transistor1    |  93.333   | 93.333 (1   epoch) |  96.545  | 96.545 (1   epoch) |     89.817      |  89.817 (1   epoch)   |    91.629    | 91.629 (1   epoch) |      85.086      |   85.086 (1   epoch)   |   98.614    | 98.614 (1   epoch) |  27.798  | 27.798 (1   epoch) |    32.836    | 32.836 (1   epoch) |   93.370    | 93.370 (1   epoch) |    19.643     | 19.643 (1   epoch)  |
|      u_block      |  69.090   | 69.090 (1   epoch) |  83.895  | 83.895 (1   epoch) |     69.612      |  69.612 (1   epoch)   |    55.622    | 55.622 (1   epoch) |      58.929      |   58.929 (1   epoch)   |   98.663    | 98.663 (1   epoch) |  19.480  | 19.480 (1   epoch) |    21.136    | 21.136 (1   epoch) |   93.609    | 93.609 (1   epoch) |    11.817     | 11.817 (1   epoch)  |
|        usb        |  59.886   | 59.886 (1   epoch) |  72.905  | 72.905 (1   epoch) |     73.110      |  73.110 (1   epoch)   |    65.979    | 65.979 (1   epoch) |      67.168      |   67.168 (1   epoch)   |   94.375    | 94.375 (1   epoch) |  3.983   | 3.983 (1   epoch)  |    10.035    | 10.035 (1   epoch) |   74.284    | 74.284 (1   epoch) |     5.282     |  5.282 (1   epoch)  |
|    usb_adaptor    |  73.229   | 73.229 (1   epoch) |  88.806  | 88.806 (1   epoch) |     65.692      |  65.692 (1   epoch)   |    53.829    | 53.829 (1   epoch) |      59.946      |   59.946 (1   epoch)   |   96.126    | 96.126 (1   epoch) |  6.280   | 6.280 (1   epoch)  |    14.694    | 14.694 (1   epoch) |   83.012    | 83.012 (1   epoch) |     7.929     |  7.929 (1   epoch)  |
|      vcpill       |  97.240   | 97.240 (1   epoch) |  98.741  | 98.741 (1   epoch) |     71.693      |  71.693 (1   epoch)   |    66.989    | 66.989 (1   epoch) |      65.306      |   65.306 (1   epoch)   |   96.535    | 96.535 (1   epoch) |  15.268  | 15.268 (1   epoch) |    22.810    | 22.810 (1   epoch) |   84.986    | 84.986 (1   epoch) |    12.873     | 12.873 (1   epoch)  |
|   wooden_beads    |  82.653   | 82.653 (1   epoch) |  93.174  | 93.174 (1   epoch) |     79.010      |  79.010 (1   epoch)   |    76.814    | 76.814 (1   epoch) |      69.091      |   69.091 (1   epoch)   |   96.341    | 96.341 (1   epoch) |  21.856  | 21.856 (1   epoch) |    28.876    | 28.876 (1   epoch) |   83.332    | 83.332 (1   epoch) |    16.875     | 16.875 (1   epoch)  |
|     woodstick     |  77.200   | 77.200 (1   epoch) |  88.951  | 88.951 (1   epoch) |     76.769      |  76.769 (1   epoch)   |    67.603    | 67.603 (1   epoch) |      57.592      |   57.592 (1   epoch)   |   93.916    | 93.916 (1   epoch) |  27.893  | 27.893 (1   epoch) |    36.085    | 36.085 (1   epoch) |   79.252    | 79.252 (1   epoch) |    22.015     | 22.015 (1   epoch)  |
|      zipper       |  99.360   | 99.360 (1   epoch) |  99.680  | 99.680 (1   epoch) |     88.368      |  88.368 (1   epoch)   |    91.533    | 91.533 (1   epoch) |      85.217      |   85.217 (1   epoch)   |   95.225    | 95.225 (1   epoch) |  10.489  | 10.489 (1   epoch) |    19.918    | 19.918 (1   epoch) |   85.051    | 85.051 (1   epoch) |    11.060     | 11.060 (1   epoch)  |
|        Avg        |  76.776   | 76.776 (1   epoch) |  87.786  | 87.786 (1   epoch) |     70.677      |  70.677 (1   epoch)   |    67.802    | 67.802 (1   epoch) |      68.367      |   68.367 (1   epoch)   |   94.829    | 94.829 (1   epoch) |  15.499  | 15.499 (1   epoch) |    22.074    | 22.074 (1   epoch) |   80.590    | 80.590 (1   epoch) |    12.840     | 12.840 (1   epoch)  |
