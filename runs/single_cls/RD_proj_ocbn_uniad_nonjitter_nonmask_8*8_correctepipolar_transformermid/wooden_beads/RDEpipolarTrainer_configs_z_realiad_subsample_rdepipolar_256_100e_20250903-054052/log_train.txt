2025-09-03 05:40:52,812 - ==> Logging on master GPU: 0
2025-09-03 05:40:52,812 - ==> Running Trainer: RDEpipolarTrainer
2025-09-03 05:40:52,812 - ==> Using GPU: [0] for Training
2025-09-03 05:40:52,812 - ==> Building model
2025-09-03 05:40:52,992 - Loading pretrained weights from url (https://download.pytorch.org/models/resnet18-5c106cde.pth)
2025-09-03 05:41:21,562 - 
------------------------------------ RDEpipolar ------------------------------------
| module                                             | #parameters or shape   | #flops       |
|:---------------------------------------------------|:-----------------------|:-------------|
| model                                              | 31.561M                | 5.207G       |
|  net_t                                             |  2.783M                |  1.838G      |
|   net_t.conv1                                      |   9.408K               |   0.154G     |
|    net_t.conv1.weight                              |    (64, 3, 7, 7)       |              |
|   net_t.bn1                                        |   0.128K               |   2.097M     |
|    net_t.bn1.weight                                |    (64,)               |              |
|    net_t.bn1.bias                                  |    (64,)               |              |
|   net_t.layer1                                     |   0.148M               |   0.606G     |
|    net_t.layer1.0                                  |    73.984K             |    0.303G    |
|     net_t.layer1.0.conv1                           |     36.864K            |     0.151G   |
|      net_t.layer1.0.conv1.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.0.bn1                             |     0.128K             |     0.524M   |
|      net_t.layer1.0.bn1.weight                     |      (64,)             |              |
|      net_t.layer1.0.bn1.bias                       |      (64,)             |              |
|     net_t.layer1.0.conv2                           |     36.864K            |     0.151G   |
|      net_t.layer1.0.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.0.bn2                             |     0.128K             |     0.524M   |
|      net_t.layer1.0.bn2.weight                     |      (64,)             |              |
|      net_t.layer1.0.bn2.bias                       |      (64,)             |              |
|    net_t.layer1.1                                  |    73.984K             |    0.303G    |
|     net_t.layer1.1.conv1                           |     36.864K            |     0.151G   |
|      net_t.layer1.1.conv1.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.1.bn1                             |     0.128K             |     0.524M   |
|      net_t.layer1.1.bn1.weight                     |      (64,)             |              |
|      net_t.layer1.1.bn1.bias                       |      (64,)             |              |
|     net_t.layer1.1.conv2                           |     36.864K            |     0.151G   |
|      net_t.layer1.1.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.1.bn2                             |     0.128K             |     0.524M   |
|      net_t.layer1.1.bn2.weight                     |      (64,)             |              |
|      net_t.layer1.1.bn2.bias                       |      (64,)             |              |
|   net_t.layer2                                     |   0.526M               |   0.538G     |
|    net_t.layer2.0                                  |    0.23M               |    0.236G    |
|     net_t.layer2.0.conv1                           |     73.728K            |     75.497M  |
|      net_t.layer2.0.conv1.weight                   |      (128, 64, 3, 3)   |              |
|     net_t.layer2.0.bn1                             |     0.256K             |     0.262M   |
|      net_t.layer2.0.bn1.weight                     |      (128,)            |              |
|      net_t.layer2.0.bn1.bias                       |      (128,)            |              |
|     net_t.layer2.0.conv2                           |     0.147M             |     0.151G   |
|      net_t.layer2.0.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_t.layer2.0.bn2                             |     0.256K             |     0.262M   |
|      net_t.layer2.0.bn2.weight                     |      (128,)            |              |
|      net_t.layer2.0.bn2.bias                       |      (128,)            |              |
|     net_t.layer2.0.downsample                      |     8.448K             |     8.651M   |
|      net_t.layer2.0.downsample.0                   |      8.192K            |      8.389M  |
|      net_t.layer2.0.downsample.1                   |      0.256K            |      0.262M  |
|    net_t.layer2.1                                  |    0.295M              |    0.303G    |
|     net_t.layer2.1.conv1                           |     0.147M             |     0.151G   |
|      net_t.layer2.1.conv1.weight                   |      (128, 128, 3, 3)  |              |
|     net_t.layer2.1.bn1                             |     0.256K             |     0.262M   |
|      net_t.layer2.1.bn1.weight                     |      (128,)            |              |
|      net_t.layer2.1.bn1.bias                       |      (128,)            |              |
|     net_t.layer2.1.conv2                           |     0.147M             |     0.151G   |
|      net_t.layer2.1.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_t.layer2.1.bn2                             |     0.256K             |     0.262M   |
|      net_t.layer2.1.bn2.weight                     |      (128,)            |              |
|      net_t.layer2.1.bn2.bias                       |      (128,)            |              |
|   net_t.layer3                                     |   2.1M                 |   0.538G     |
|    net_t.layer3.0                                  |    0.919M              |    0.235G    |
|     net_t.layer3.0.conv1                           |     0.295M             |     75.497M  |
|      net_t.layer3.0.conv1.weight                   |      (256, 128, 3, 3)  |              |
|     net_t.layer3.0.bn1                             |     0.512K             |     0.131M   |
|      net_t.layer3.0.bn1.weight                     |      (256,)            |              |
|      net_t.layer3.0.bn1.bias                       |      (256,)            |              |
|     net_t.layer3.0.conv2                           |     0.59M              |     0.151G   |
|      net_t.layer3.0.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_t.layer3.0.bn2                             |     0.512K             |     0.131M   |
|      net_t.layer3.0.bn2.weight                     |      (256,)            |              |
|      net_t.layer3.0.bn2.bias                       |      (256,)            |              |
|     net_t.layer3.0.downsample                      |     33.28K             |     8.52M    |
|      net_t.layer3.0.downsample.0                   |      32.768K           |      8.389M  |
|      net_t.layer3.0.downsample.1                   |      0.512K            |      0.131M  |
|    net_t.layer3.1                                  |    1.181M              |    0.302G    |
|     net_t.layer3.1.conv1                           |     0.59M              |     0.151G   |
|      net_t.layer3.1.conv1.weight                   |      (256, 256, 3, 3)  |              |
|     net_t.layer3.1.bn1                             |     0.512K             |     0.131M   |
|      net_t.layer3.1.bn1.weight                     |      (256,)            |              |
|      net_t.layer3.1.bn1.bias                       |      (256,)            |              |
|     net_t.layer3.1.conv2                           |     0.59M              |     0.151G   |
|      net_t.layer3.1.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_t.layer3.1.bn2                             |     0.512K             |     0.131M   |
|      net_t.layer3.1.bn2.weight                     |      (256,)            |              |
|      net_t.layer3.1.bn2.bias                       |      (256,)            |              |
|  mff_oce                                           |  16.401M               |  1.234G      |
|   mff_oce.bn_layer                                 |   15.736M              |   1.007G     |
|    mff_oce.bn_layer.0                              |    6.295M              |    0.403G    |
|     mff_oce.bn_layer.0.conv1                       |     3.539M             |     0.226G   |
|      mff_oce.bn_layer.0.conv1.weight               |      (512, 768, 3, 3)  |              |
|     mff_oce.bn_layer.0.bn1                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.0.bn1.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.0.bn1.bias                   |      (512,)            |              |
|     mff_oce.bn_layer.0.conv2                       |     2.359M             |     0.151G   |
|      mff_oce.bn_layer.0.conv2.weight               |      (512, 512, 3, 3)  |              |
|     mff_oce.bn_layer.0.bn2                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.0.bn2.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.0.bn2.bias                   |      (512,)            |              |
|     mff_oce.bn_layer.0.downsample                  |     0.394M             |     25.231M  |
|      mff_oce.bn_layer.0.downsample.0               |      0.393M            |      25.166M |
|      mff_oce.bn_layer.0.downsample.1               |      1.024K            |      65.536K |
|    mff_oce.bn_layer.1                              |    4.721M              |    0.302G    |
|     mff_oce.bn_layer.1.conv1                       |     2.359M             |     0.151G   |
|      mff_oce.bn_layer.1.conv1.weight               |      (512, 512, 3, 3)  |              |
|     mff_oce.bn_layer.1.bn1                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.1.bn1.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.1.bn1.bias                   |      (512,)            |              |
|     mff_oce.bn_layer.1.conv2                       |     2.359M             |     0.151G   |
|      mff_oce.bn_layer.1.conv2.weight               |      (512, 512, 3, 3)  |              |
|     mff_oce.bn_layer.1.bn2                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.1.bn2.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.1.bn2.bias                   |      (512,)            |              |
|    mff_oce.bn_layer.2                              |    4.721M              |    0.302G    |
|     mff_oce.bn_layer.2.conv1                       |     2.359M             |     0.151G   |
|      mff_oce.bn_layer.2.conv1.weight               |      (512, 512, 3, 3)  |              |
|     mff_oce.bn_layer.2.bn1                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.2.bn1.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.2.bn1.bias                   |      (512,)            |              |
|     mff_oce.bn_layer.2.conv2                       |     2.359M             |     0.151G   |
|      mff_oce.bn_layer.2.conv2.weight               |      (512, 512, 3, 3)  |              |
|     mff_oce.bn_layer.2.bn2                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.2.bn2.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.2.bn2.bias                   |      (512,)            |              |
|   mff_oce.conv1                                    |   73.728K              |   75.497M    |
|    mff_oce.conv1.weight                            |    (128, 64, 3, 3)     |              |
|   mff_oce.bn1                                      |   0.256K               |   0.262M     |
|    mff_oce.bn1.weight                              |    (128,)              |              |
|    mff_oce.bn1.bias                                |    (128,)              |              |
|   mff_oce.conv2                                    |   0.295M               |   75.497M    |
|    mff_oce.conv2.weight                            |    (256, 128, 3, 3)    |              |
|   mff_oce.bn2                                      |   0.512K               |   0.131M     |
|    mff_oce.bn2.weight                              |    (256,)              |              |
|    mff_oce.bn2.bias                                |    (256,)              |              |
|   mff_oce.conv3                                    |   0.295M               |   75.497M    |
|    mff_oce.conv3.weight                            |    (256, 128, 3, 3)    |              |
|   mff_oce.bn3                                      |   0.512K               |   0.131M     |
|    mff_oce.bn3.weight                              |    (256,)              |              |
|    mff_oce.bn3.bias                                |    (256,)              |              |
|  net_s                                             |  3.703M                |  1.565G      |
|   net_s.layer1                                     |   2.821M               |   0.521G     |
|    net_s.layer1.0                                  |    1.64M               |    0.218G    |
|     net_s.layer1.0.conv1                           |     0.524M             |     33.554M  |
|      net_s.layer1.0.conv1.weight                   |      (512, 256, 2, 2)  |              |
|     net_s.layer1.0.bn1                             |     0.512K             |     0.131M   |
|      net_s.layer1.0.bn1.weight                     |      (256,)            |              |
|      net_s.layer1.0.bn1.bias                       |      (256,)            |              |
|     net_s.layer1.0.conv2                           |     0.59M              |     0.151G   |
|      net_s.layer1.0.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_s.layer1.0.bn2                             |     0.512K             |     0.131M   |
|      net_s.layer1.0.bn2.weight                     |      (256,)            |              |
|      net_s.layer1.0.bn2.bias                       |      (256,)            |              |
|     net_s.layer1.0.upsample                        |     0.525M             |     33.686M  |
|      net_s.layer1.0.upsample.0                     |      0.524M            |      33.554M |
|      net_s.layer1.0.upsample.1                     |      0.512K            |      0.131M  |
|    net_s.layer1.1                                  |    1.181M              |    0.302G    |
|     net_s.layer1.1.conv1                           |     0.59M              |     0.151G   |
|      net_s.layer1.1.conv1.weight                   |      (256, 256, 3, 3)  |              |
|     net_s.layer1.1.bn1                             |     0.512K             |     0.131M   |
|      net_s.layer1.1.bn1.weight                     |      (256,)            |              |
|      net_s.layer1.1.bn1.bias                       |      (256,)            |              |
|     net_s.layer1.1.conv2                           |     0.59M              |     0.151G   |
|      net_s.layer1.1.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_s.layer1.1.bn2                             |     0.512K             |     0.131M   |
|      net_s.layer1.1.bn2.weight                     |      (256,)            |              |
|      net_s.layer1.1.bn2.bias                       |      (256,)            |              |
|   net_s.layer2                                     |   0.706M               |   0.521G     |
|    net_s.layer2.0                                  |    0.41M               |    0.219G    |
|     net_s.layer2.0.conv1                           |     0.131M             |     33.554M  |
|      net_s.layer2.0.conv1.weight                   |      (256, 128, 2, 2)  |              |
|     net_s.layer2.0.bn1                             |     0.256K             |     0.262M   |
|      net_s.layer2.0.bn1.weight                     |      (128,)            |              |
|      net_s.layer2.0.bn1.bias                       |      (128,)            |              |
|     net_s.layer2.0.conv2                           |     0.147M             |     0.151G   |
|      net_s.layer2.0.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_s.layer2.0.bn2                             |     0.256K             |     0.262M   |
|      net_s.layer2.0.bn2.weight                     |      (128,)            |              |
|      net_s.layer2.0.bn2.bias                       |      (128,)            |              |
|     net_s.layer2.0.upsample                        |     0.131M             |     33.817M  |
|      net_s.layer2.0.upsample.0                     |      0.131M            |      33.554M |
|      net_s.layer2.0.upsample.1                     |      0.256K            |      0.262M  |
|    net_s.layer2.1                                  |    0.295M              |    0.303G    |
|     net_s.layer2.1.conv1                           |     0.147M             |     0.151G   |
|      net_s.layer2.1.conv1.weight                   |      (128, 128, 3, 3)  |              |
|     net_s.layer2.1.bn1                             |     0.256K             |     0.262M   |
|      net_s.layer2.1.bn1.weight                     |      (128,)            |              |
|      net_s.layer2.1.bn1.bias                       |      (128,)            |              |
|     net_s.layer2.1.conv2                           |     0.147M             |     0.151G   |
|      net_s.layer2.1.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_s.layer2.1.bn2                             |     0.256K             |     0.262M   |
|      net_s.layer2.1.bn2.weight                     |      (128,)            |              |
|      net_s.layer2.1.bn2.bias                       |      (128,)            |              |
|   net_s.layer3                                     |   0.177M               |   0.523G     |
|    net_s.layer3.0                                  |    0.103M              |    0.22G     |
|     net_s.layer3.0.conv1                           |     32.768K            |     33.554M  |
|      net_s.layer3.0.conv1.weight                   |      (128, 64, 2, 2)   |              |
|     net_s.layer3.0.bn1                             |     0.128K             |     0.524M   |
|      net_s.layer3.0.bn1.weight                     |      (64,)             |              |
|      net_s.layer3.0.bn1.bias                       |      (64,)             |              |
|     net_s.layer3.0.conv2                           |     36.864K            |     0.151G   |
|      net_s.layer3.0.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_s.layer3.0.bn2                             |     0.128K             |     0.524M   |
|      net_s.layer3.0.bn2.weight                     |      (64,)             |              |
|      net_s.layer3.0.bn2.bias                       |      (64,)             |              |
|     net_s.layer3.0.upsample                        |     32.896K            |     34.079M  |
|      net_s.layer3.0.upsample.0                     |      32.768K           |      33.554M |
|      net_s.layer3.0.upsample.1                     |      0.128K            |      0.524M  |
|    net_s.layer3.1                                  |    73.984K             |    0.303G    |
|     net_s.layer3.1.conv1                           |     36.864K            |     0.151G   |
|      net_s.layer3.1.conv1.weight                   |      (64, 64, 3, 3)    |              |
|     net_s.layer3.1.bn1                             |     0.128K             |     0.524M   |
|      net_s.layer3.1.bn1.weight                     |      (64,)             |              |
|      net_s.layer3.1.bn1.bias                       |      (64,)             |              |
|     net_s.layer3.1.conv2                           |     36.864K            |     0.151G   |
|      net_s.layer3.1.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_s.layer3.1.bn2                             |     0.128K             |     0.524M   |
|      net_s.layer3.1.bn2.weight                     |      (64,)             |              |
|      net_s.layer3.1.bn2.bias                       |      (64,)             |              |
|  proj_layer                                        |  0.969M                |  0.57G       |
|   proj_layer.proj_a.proj                           |   46.224K              |   0.191G     |
|    proj_layer.proj_a.proj.0                        |    18.464K             |    75.497M   |
|     proj_layer.proj_a.proj.0.weight                |     (32, 64, 3, 3)     |              |
|     proj_layer.proj_a.proj.0.bias                  |     (32,)              |              |
|    proj_layer.proj_a.proj.3                        |    4.624K              |    18.874M   |
|     proj_layer.proj_a.proj.3.weight                |     (16, 32, 3, 3)     |              |
|     proj_layer.proj_a.proj.3.bias                  |     (16,)              |              |
|    proj_layer.proj_a.proj.6                        |    4.64K               |    18.874M   |
|     proj_layer.proj_a.proj.6.weight                |     (32, 16, 3, 3)     |              |
|     proj_layer.proj_a.proj.6.bias                  |     (32,)              |              |
|    proj_layer.proj_a.proj.9                        |    18.496K             |    75.497M   |
|     proj_layer.proj_a.proj.9.weight                |     (64, 32, 3, 3)     |              |
|     proj_layer.proj_a.proj.9.bias                  |     (64,)              |              |
|    proj_layer.proj_a.proj.1                        |                        |    0.524M    |
|    proj_layer.proj_a.proj.4                        |                        |    0.262M    |
|    proj_layer.proj_a.proj.7                        |                        |    0.524M    |
|    proj_layer.proj_a.proj.10                       |                        |    1.049M    |
|   proj_layer.proj_b.proj                           |   0.185M               |   0.19G      |
|    proj_layer.proj_b.proj.0                        |    73.792K             |    75.497M   |
|     proj_layer.proj_b.proj.0.weight                |     (64, 128, 3, 3)    |              |
|     proj_layer.proj_b.proj.0.bias                  |     (64,)              |              |
|    proj_layer.proj_b.proj.3                        |    18.464K             |    18.874M   |
|     proj_layer.proj_b.proj.3.weight                |     (32, 64, 3, 3)     |              |
|     proj_layer.proj_b.proj.3.bias                  |     (32,)              |              |
|    proj_layer.proj_b.proj.6                        |    18.496K             |    18.874M   |
|     proj_layer.proj_b.proj.6.weight                |     (64, 32, 3, 3)     |              |
|     proj_layer.proj_b.proj.6.bias                  |     (64,)              |              |
|    proj_layer.proj_b.proj.9                        |    73.856K             |    75.497M   |
|     proj_layer.proj_b.proj.9.weight                |     (128, 64, 3, 3)    |              |
|     proj_layer.proj_b.proj.9.bias                  |     (128,)             |              |
|    proj_layer.proj_b.proj.1                        |                        |    0.262M    |
|    proj_layer.proj_b.proj.4                        |                        |    0.131M    |
|    proj_layer.proj_b.proj.7                        |                        |    0.262M    |
|    proj_layer.proj_b.proj.10                       |                        |    0.524M    |
|   proj_layer.proj_c.proj                           |   0.738M               |   0.189G     |
|    proj_layer.proj_c.proj.0                        |    0.295M              |    75.497M   |
|     proj_layer.proj_c.proj.0.weight                |     (128, 256, 3, 3)   |              |
|     proj_layer.proj_c.proj.0.bias                  |     (128,)             |              |
|    proj_layer.proj_c.proj.3                        |    73.792K             |    18.874M   |
|     proj_layer.proj_c.proj.3.weight                |     (64, 128, 3, 3)    |              |
|     proj_layer.proj_c.proj.3.bias                  |     (64,)              |              |
|    proj_layer.proj_c.proj.6                        |    73.856K             |    18.874M   |
|     proj_layer.proj_c.proj.6.weight                |     (128, 64, 3, 3)    |              |
|     proj_layer.proj_c.proj.6.bias                  |     (128,)             |              |
|    proj_layer.proj_c.proj.9                        |    0.295M              |    75.497M   |
|     proj_layer.proj_c.proj.9.weight                |     (256, 128, 3, 3)   |              |
|     proj_layer.proj_c.proj.9.bias                  |     (256,)             |              |
|    proj_layer.proj_c.proj.1                        |                        |    0.131M    |
|    proj_layer.proj_c.proj.4                        |                        |    65.536K   |
|    proj_layer.proj_c.proj.7                        |                        |    0.131M    |
|    proj_layer.proj_c.proj.10                       |                        |    0.262M    |
|  net_ad                                            |  7.706M                |              |
|   net_ad.pos_embed                                 |   2.048K               |              |
|    net_ad.pos_embed.row_embed                      |    1.024K              |              |
|     net_ad.pos_embed.row_embed.weight              |     (8, 128)           |              |
|    net_ad.pos_embed.col_embed                      |    1.024K              |              |
|     net_ad.pos_embed.col_embed.weight              |     (8, 128)           |              |
|   net_ad.transformer                               |   7.441M               |              |
|    net_ad.transformer.encoder.layers               |    3.161M              |              |
|     net_ad.transformer.encoder.layers.0            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.0.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.0.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.0.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.0.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.0.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.0.norm_mid  |      0.512K            |              |
|     net_ad.transformer.encoder.layers.1            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.1.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.1.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.1.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.1.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.1.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.1.norm_mid  |      0.512K            |              |
|     net_ad.transformer.encoder.layers.2            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.2.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.2.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.2.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.2.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.2.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.2.norm_mid  |      0.512K            |              |
|     net_ad.transformer.encoder.layers.3            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.3.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.3.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.3.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.3.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.3.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.3.norm_mid  |      0.512K            |              |
|    net_ad.transformer.decoder                      |    4.28M               |              |
|     net_ad.transformer.decoder.layers              |     4.279M             |              |
|      net_ad.transformer.decoder.layers.0           |      1.07M             |              |
|      net_ad.transformer.decoder.layers.1           |      1.07M             |              |
|      net_ad.transformer.decoder.layers.2           |      1.07M             |              |
|      net_ad.transformer.decoder.layers.3           |      1.07M             |              |
|     net_ad.transformer.decoder.norm                |     0.512K             |              |
|      net_ad.transformer.decoder.norm.weight        |      (256,)            |              |
|      net_ad.transformer.decoder.norm.bias          |      (256,)            |              |
|   net_ad.input_proj                                |   0.131M               |              |
|    net_ad.input_proj.weight                        |    (256, 512)          |              |
|    net_ad.input_proj.bias                          |    (256,)              |              |
|   net_ad.output_proj                               |   0.132M               |              |
|    net_ad.output_proj.weight                       |    (512, 256)          |              |
|    net_ad.output_proj.bias                         |    (512,)              |              |
------------------------------------------------------------------------------------
2025-09-03 05:41:21,563 - ==> Creating optimizer
2025-09-03 05:41:21,564 - ==> Loading dataset: RealIAD
2025-09-03 05:41:21,574 - ==> ********** cfg ********** 
fvcore_is                            : True                                
fvcore_b                             : 1                                   
fvcore_c                             : 3                                   
epoch_full                           : 100                                 
metrics                              : ['S_AUROC', 'S_AUPR', 'mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mAUPRO_px', 'mIoU_max_px']
use_adeval                           : True                                
evaluator.kwargs                     : {'metrics': ['S_AUROC', 'S_AUPR', 'mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mAUPRO_px', 'mIoU_max_px'], 'pooling_ks': [16, 16], 'max_step_aupro': 100, 'use_adeval': True}
optim.lr                             : 5e-05                               
optim.kwargs                         : {'name': 'adamw', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
trainer.name                         : RDEpipolarTrainer                   
trainer.checkpoint                   : runs/single_cls/rdepipolar_256_100e/wooden_beads
trainer.logdir_sub                   :                                     
trainer.resume_dir                   :                                     
trainer.cuda_deterministic           : False                               
trainer.epoch_full                   : 100                                 
trainer.scheduler_kwargs             : {'name': 'step', 'lr_noise': None, 'noise_pct': 0.67, 'noise_std': 1.0, 'noise_seed': 42, 'lr_min': 5e-07, 'warmup_lr': 5.0000000000000004e-08, 'warmup_iters': -1, 'cooldown_iters': 0, 'warmup_epochs': 0, 'cooldown_epochs': 0, 'use_iters': True, 'patience_iters': 0, 'patience_epochs': 0, 'decay_iters': 0, 'decay_epochs': 80, 'cycle_decay': 0.1, 'decay_rate': 0.1}
trainer.mixup_kwargs                 : {'mixup_alpha': 0.8, 'cutmix_alpha': 1.0, 'cutmix_minmax': None, 'prob': 0.0, 'switch_prob': 0.5, 'mode': 'batch', 'correct_lam': True, 'label_smoothing': 0.1}
trainer.test_start_epoch             : 100                                 
trainer.test_per_epoch               : 100                                 
trainer.find_unused_parameters       : False                               
trainer.sync_BN                      : apex                                
trainer.dist_BN                      :                                     
trainer.scaler                       : none                                
trainer.data.batch_size              : 4                                   
trainer.data.batch_size_per_gpu      : 4                                   
trainer.data.batch_size_test         : 4                                   
trainer.data.batch_size_per_gpu_test : 4                                   
trainer.data.num_workers_per_gpu     : 8                                   
trainer.data.drop_last               : True                                
trainer.data.pin_memory              : True                                
trainer.data.persistent_workers      : False                               
trainer.data.num_workers             : 8                                   
trainer.iter                         : 0                                   
trainer.epoch                        : 0                                   
trainer.iter_full                    : 5400                                
trainer.metric_recorder              : {'S_AUROC_wooden_beads': [], 'S_AUPR_wooden_beads': [], 'mAUROC_sp_max_wooden_beads': [], 'mAP_sp_max_wooden_beads': [], 'mF1_max_sp_max_wooden_beads': [], 'mAUROC_px_wooden_beads': [], 'mAP_px_wooden_beads': [], 'mF1_max_px_wooden_beads': [], 'mAUPRO_px_wooden_beads': [], 'mIoU_max_px_wooden_beads': []}
loss.loss_terms                      : [{'type': 'CosLoss', 'name': 'cos', 'avg': False, 'lam': 1.0}]
loss.clip_grad                       : 5.0                                 
loss.create_graph                    : False                               
loss.retain_graph                    : False                               
adv                                  : False                               
logging.log_terms_train              : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'data_t', 'fmt': ':>5.3f'}, {'name': 'optim_t', 'fmt': ':>5.3f'}, {'name': 'lr', 'fmt': ':>7.6f'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.log_terms_test               : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.train_reset_log_per          : 50                                  
logging.train_log_per                : 50                                  
logging.test_log_per                 : 50                                  
data.sampler                         : naive                               
data.loader_type                     : pil                                 
data.loader_type_target              : pil_L                               
data.type                            : RealIAD                             
data.root                            : /home/albus/DataSets/REAL-IAD/realiad_256
data.meta                            : meta.json                           
data.cls_names                       : wooden_beads                        
data.train_transforms                : [{'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.test_transforms                 : [{'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.target_transforms               : [{'type': 'ToTensor'}]              
data.use_sample                      : True                                
data.views                           : []                                  
data.train_size                      : 54                                  
data.test_size                       : 196                                 
data.train_length                    : 218                                 
data.test_length                     : 783                                 
model_t.name                         : timm_resnet18                       
model_t.kwargs                       : {'pretrained': True, 'checkpoint_path': '', 'strict': False, 'features_only': True, 'out_indices': [1, 2, 3]}
model_s.name                         : de_resnet18                         
model_s.kwargs                       : {'pretrained': False, 'checkpoint_path': '', 'strict': False}
model.name                           : rdepipolar                          
model.kwargs                         : {'pretrained': False, 'checkpoint_path': '', 'strict': True, 'model_t': Namespace(kwargs={'pretrained': True, 'checkpoint_path': '', 'strict': False, 'features_only': True, 'out_indices': [1, 2, 3]}, name='timm_resnet18'), 'model_s': Namespace(kwargs={'pretrained': False, 'checkpoint_path': '', 'strict': False}, name='de_resnet18')}
seed                                 : 42                                  
size                                 : 256                                 
warmup_epochs                        : 0                                   
test_start_epoch                     : 100                                 
test_per_epoch                       : 100                                 
batch_train                          : 4                                   
batch_test_per                       : 4                                   
lr                                   : 5e-05                               
weight_decay                         : 0.0001                              
cfg_path                             : configs.z_realiad_subsample.rdepipolar_256_100e
mode                                 : train                               
sleep                                : -1                                  
memory                               : -1                                  
dist_url                             : env://                              
logger_rank                          : 0                                   
opts                                 : ['data.cls_names=wooden_beads', 'trainer.checkpoint=runs/single_cls/rdepipolar_256_100e/wooden_beads']
command                              : python3 -m torch.distributed.launch --nproc_per_node=$nproc_per_node --nnodes=$nnodes --node_rank=$node_rank --master_addr=$master_addr --master_port=$master_port --use_env run.py -c configs.z_realiad_subsample.rdepipolar_256_100e -m train --sleep -1 --memory -1 --dist_url env:// --logger_rank 0 data.cls_names=wooden_beads trainer.checkpoint=runs/single_cls/rdepipolar_256_100e/wooden_beads
task_start_time                      : 1870343.71749276                    
dist                                 : False                               
world_size                           : 1                                   
rank                                 : 0                                   
local_rank                           : 0                                   
ngpus_per_node                       : 1                                   
nnodes                               : 1                                   
master                               : True                                
logdir                               : runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052
logger.filters                       : []                                  
logger.name                          : root                                
logger.level                         : 20                                  
logger.parent                        : None                                
logger.propagate                     : True                                
logger.disabled                      : False                               
logdir_train                         : runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052/show_train
logdir_test                          : runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052/show_test
2025-09-03 05:41:21,574 - ==> Starting training with 1 nodes x 1 GPUs
2025-09-03 05:41:26,397 - Train: 0.93% [50/5400]  [0.9/100.0] [batch_t 0.061 (0.092)] [data_t 0.002] [optim_t 0.060] [lr 0.000050] [cos 1.161 (1.482)]
2025-09-03 05:41:26,656 - ==> Total time: 0:00:33	 Eta: 0:55:51 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:41:30,082 - Train: 1.85% [100/5400]  [1.9/100.0] [batch_t 0.064 (0.066)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.871 (0.982)]
2025-09-03 05:41:30,588 - ==> Total time: 0:00:37	 Eta: 0:30:51 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:41:33,850 - Train: 2.78% [150/5400]  [2.8/100.0] [batch_t 0.062 (0.067)] [data_t 0.002] [optim_t 0.060] [lr 0.000050] [cos 0.724 (0.781)]
2025-09-03 05:41:34,610 - ==> Total time: 0:00:41	 Eta: 0:22:31 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:41:37,586 - Train: 3.70% [200/5400]  [3.7/100.0] [batch_t 0.063 (0.065)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.636 (0.670)]
2025-09-03 05:41:38,610 - ==> Total time: 0:00:45	 Eta: 0:18:19 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:41:41,331 - Train: 4.63% [250/5400]  [4.6/100.0] [batch_t 0.062 (0.065)] [data_t 0.002] [optim_t 0.060] [lr 0.000050] [cos 0.567 (0.595)]
2025-09-03 05:41:42,604 - ==> Total time: 0:00:49	 Eta: 0:15:46 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:41:45,103 - Train: 5.56% [300/5400]  [5.6/100.0] [batch_t 0.065 (0.067)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.511 (0.531)]
2025-09-03 05:41:46,633 - ==> Total time: 0:00:53	 Eta: 0:14:03 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:41:48,871 - Train: 6.48% [350/5400]  [6.5/100.0] [batch_t 0.072 (0.068)] [data_t 0.002] [optim_t 0.070] [lr 0.000050] [cos 0.467 (0.485)]
2025-09-03 05:41:50,657 - ==> Total time: 0:00:57	 Eta: 0:12:48 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:41:52,648 - Train: 7.41% [400/5400]  [7.4/100.0] [batch_t 0.064 (0.065)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.448 (0.445)]
2025-09-03 05:41:54,698 - ==> Total time: 0:01:01	 Eta: 0:11:51 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:41:56,399 - Train: 8.33% [450/5400]  [8.3/100.0] [batch_t 0.066 (0.070)] [data_t 0.002] [optim_t 0.065] [lr 0.000050] [cos 0.427 (0.417)]
2025-09-03 05:41:58,702 - ==> Total time: 0:01:05	 Eta: 0:11:06 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:00,135 - Train: 9.26% [500/5400]  [9.3/100.0] [batch_t 0.066 (0.070)] [data_t 0.002] [optim_t 0.064] [lr 0.000050] [cos 0.366 (0.384)]
2025-09-03 05:42:02,709 - ==> Total time: 0:01:09	 Eta: 0:10:29 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:03,873 - Train: 10.19% [550/5400]  [10.2/100.0] [batch_t 0.065 (0.071)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.361 (0.370)]
2025-09-03 05:42:06,712 - ==> Total time: 0:01:13	 Eta: 0:09:57 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:07,617 - Train: 11.11% [600/5400]  [11.1/100.0] [batch_t 0.063 (0.078)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.332 (0.346)]
2025-09-03 05:42:10,706 - ==> Total time: 0:01:17	 Eta: 0:09:31 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:11,365 - Train: 12.04% [650/5400]  [12.0/100.0] [batch_t 0.063 (0.103)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.322 (0.317)]
2025-09-03 05:42:14,607 - Train: 12.96% [700/5400]  [13.0/100.0] [batch_t 0.064 (0.065)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.327 (0.320)]
2025-09-03 05:42:14,735 - ==> Total time: 0:01:21	 Eta: 0:09:08 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:18,348 - Train: 13.89% [750/5400]  [13.9/100.0] [batch_t 0.062 (0.066)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.295 (0.306)]
2025-09-03 05:42:18,732 - ==> Total time: 0:01:25	 Eta: 0:08:47 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:22,136 - Train: 14.81% [800/5400]  [14.8/100.0] [batch_t 0.063 (0.066)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.303 (0.294)]
2025-09-03 05:42:22,777 - ==> Total time: 0:01:29	 Eta: 0:08:29 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:25,909 - Train: 15.74% [850/5400]  [15.7/100.0] [batch_t 0.063 (0.067)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.278 (0.285)]
2025-09-03 05:42:26,808 - ==> Total time: 0:01:34	 Eta: 0:08:13 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:29,631 - Train: 16.67% [900/5400]  [16.7/100.0] [batch_t 0.063 (0.064)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.288 (0.273)]
2025-09-03 05:42:30,778 - ==> Total time: 0:01:37	 Eta: 0:07:58 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:33,403 - Train: 17.59% [950/5400]  [17.6/100.0] [batch_t 0.063 (0.066)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.260 (0.266)]
2025-09-03 05:42:34,815 - ==> Total time: 0:01:42	 Eta: 0:07:44 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:37,155 - Train: 18.52% [1000/5400]  [18.5/100.0] [batch_t 0.064 (0.067)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.250 (0.262)]
2025-09-03 05:42:38,826 - ==> Total time: 0:01:46	 Eta: 0:07:31 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:40,907 - Train: 19.44% [1050/5400]  [19.4/100.0] [batch_t 0.065 (0.069)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.237 (0.250)]
2025-09-03 05:42:42,834 - ==> Total time: 0:01:50	 Eta: 0:07:20 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:44,707 - Train: 20.37% [1100/5400]  [20.4/100.0] [batch_t 0.063 (0.066)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.238 (0.247)]
2025-09-03 05:42:46,883 - ==> Total time: 0:01:54	 Eta: 0:07:09 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:48,475 - Train: 21.30% [1150/5400]  [21.3/100.0] [batch_t 0.065 (0.067)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.226 (0.242)]
2025-09-03 05:42:50,909 - ==> Total time: 0:01:58	 Eta: 0:06:58 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:52,278 - Train: 22.22% [1200/5400]  [22.2/100.0] [batch_t 0.062 (0.070)] [data_t 0.002] [optim_t 0.060] [lr 0.000050] [cos 0.229 (0.231)]
2025-09-03 05:42:54,960 - ==> Total time: 0:02:02	 Eta: 0:06:48 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:56,012 - Train: 23.15% [1250/5400]  [23.1/100.0] [batch_t 0.066 (0.076)] [data_t 0.002] [optim_t 0.064] [lr 0.000050] [cos 0.237 (0.231)]
2025-09-03 05:42:58,983 - ==> Total time: 0:02:06	 Eta: 0:06:39 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:42:59,795 - Train: 24.07% [1300/5400]  [24.1/100.0] [batch_t 0.063 (0.077)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.231 (0.230)]
2025-09-03 05:43:03,008 - Train: 25.00% [1350/5400]  [25.0/100.0] [batch_t 0.065 (0.064)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.212 (0.228)]
2025-09-03 05:43:03,009 - ==> Total time: 0:02:10	 Eta: 0:06:30 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:06,779 - Train: 25.93% [1400/5400]  [25.9/100.0] [batch_t 0.064 (0.065)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.213 (0.224)]
2025-09-03 05:43:07,035 - ==> Total time: 0:02:14	 Eta: 0:06:22 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:10,580 - Train: 26.85% [1450/5400]  [26.9/100.0] [batch_t 0.065 (0.067)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.212 (0.219)]
2025-09-03 05:43:11,096 - ==> Total time: 0:02:18	 Eta: 0:06:13 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:14,338 - Train: 27.78% [1500/5400]  [27.8/100.0] [batch_t 0.065 (0.066)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.209 (0.211)]
2025-09-03 05:43:15,100 - ==> Total time: 0:02:22	 Eta: 0:06:05 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:18,119 - Train: 28.70% [1550/5400]  [28.7/100.0] [batch_t 0.063 (0.066)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.200 (0.207)]
2025-09-03 05:43:19,141 - ==> Total time: 0:02:26	 Eta: 0:05:58 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:21,896 - Train: 29.63% [1600/5400]  [29.6/100.0] [batch_t 0.064 (0.067)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.203 (0.204)]
2025-09-03 05:43:23,175 - ==> Total time: 0:02:30	 Eta: 0:05:50 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:25,672 - Train: 30.56% [1650/5400]  [30.6/100.0] [batch_t 0.067 (0.068)] [data_t 0.002] [optim_t 0.065] [lr 0.000050] [cos 0.197 (0.200)]
2025-09-03 05:43:27,222 - ==> Total time: 0:02:34	 Eta: 0:05:43 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:29,428 - Train: 31.48% [1700/5400]  [31.5/100.0] [batch_t 0.062 (0.068)] [data_t 0.002] [optim_t 0.060] [lr 0.000050] [cos 0.187 (0.202)]
2025-09-03 05:43:31,232 - ==> Total time: 0:02:38	 Eta: 0:05:36 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:33,243 - Train: 32.41% [1750/5400]  [32.4/100.0] [batch_t 0.064 (0.069)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.196 (0.194)]
2025-09-03 05:43:35,293 - ==> Total time: 0:02:42	 Eta: 0:05:29 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:37,011 - Train: 33.33% [1800/5400]  [33.3/100.0] [batch_t 0.063 (0.068)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.191 (0.191)]
2025-09-03 05:43:39,335 - ==> Total time: 0:02:46	 Eta: 0:05:23 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:40,772 - Train: 34.26% [1850/5400]  [34.3/100.0] [batch_t 0.064 (0.066)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.196 (0.190)]
2025-09-03 05:43:43,358 - ==> Total time: 0:02:50	 Eta: 0:05:16 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:44,527 - Train: 35.19% [1900/5400]  [35.2/100.0] [batch_t 0.064 (0.066)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.188 (0.184)]
2025-09-03 05:43:47,348 - ==> Total time: 0:02:54	 Eta: 0:05:10 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:48,271 - Train: 36.11% [1950/5400]  [36.1/100.0] [batch_t 0.067 (0.071)] [data_t 0.002] [optim_t 0.065] [lr 0.000050] [cos 0.200 (0.189)]
2025-09-03 05:43:51,383 - ==> Total time: 0:02:58	 Eta: 0:05:04 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:52,050 - Train: 37.04% [2000/5400]  [37.0/100.0] [batch_t 0.065 (0.097)] [data_t 0.002] [optim_t 0.064] [lr 0.000050] [cos 0.179 (0.184)]
2025-09-03 05:43:55,254 - Train: 37.96% [2050/5400]  [38.0/100.0] [batch_t 0.063 (0.064)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.183 (0.183)]
2025-09-03 05:43:55,385 - ==> Total time: 0:03:02	 Eta: 0:04:57 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:43:59,018 - Train: 38.89% [2100/5400]  [38.9/100.0] [batch_t 0.063 (0.066)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.190 (0.179)]
2025-09-03 05:43:59,398 - ==> Total time: 0:03:06	 Eta: 0:04:51 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:02,785 - Train: 39.81% [2150/5400]  [39.8/100.0] [batch_t 0.065 (0.065)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.178 (0.176)]
2025-09-03 05:44:03,421 - ==> Total time: 0:03:10	 Eta: 0:04:45 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:06,543 - Train: 40.74% [2200/5400]  [40.7/100.0] [batch_t 0.064 (0.067)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.176 (0.177)]
2025-09-03 05:44:07,435 - ==> Total time: 0:03:14	 Eta: 0:04:40 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:10,310 - Train: 41.67% [2250/5400]  [41.7/100.0] [batch_t 0.065 (0.067)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.172 (0.175)]
2025-09-03 05:44:11,460 - ==> Total time: 0:03:18	 Eta: 0:04:34 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:14,127 - Train: 42.59% [2300/5400]  [42.6/100.0] [batch_t 0.066 (0.067)] [data_t 0.002] [optim_t 0.064] [lr 0.000050] [cos 0.167 (0.170)]
2025-09-03 05:44:15,541 - ==> Total time: 0:03:22	 Eta: 0:04:28 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:17,943 - Train: 43.52% [2350/5400]  [43.5/100.0] [batch_t 0.064 (0.068)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.175 (0.170)]
2025-09-03 05:44:19,610 - ==> Total time: 0:03:26	 Eta: 0:04:23 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:21,771 - Train: 44.44% [2400/5400]  [44.4/100.0] [batch_t 0.066 (0.069)] [data_t 0.002] [optim_t 0.065] [lr 0.000050] [cos 0.169 (0.167)]
2025-09-03 05:44:23,708 - ==> Total time: 0:03:30	 Eta: 0:04:17 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:25,543 - Train: 45.37% [2450/5400]  [45.4/100.0] [batch_t 0.064 (0.069)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.153 (0.166)]
2025-09-03 05:44:27,717 - ==> Total time: 0:03:34	 Eta: 0:04:12 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:29,291 - Train: 46.30% [2500/5400]  [46.3/100.0] [batch_t 0.066 (0.071)] [data_t 0.002] [optim_t 0.064] [lr 0.000050] [cos 0.152 (0.163)]
2025-09-03 05:44:31,727 - ==> Total time: 0:03:38	 Eta: 0:04:06 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:33,071 - Train: 47.22% [2550/5400]  [47.2/100.0] [batch_t 0.065 (0.071)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.156 (0.161)]
2025-09-03 05:44:35,769 - ==> Total time: 0:03:42	 Eta: 0:04:01 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:36,868 - Train: 48.15% [2600/5400]  [48.1/100.0] [batch_t 0.064 (0.072)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.158 (0.162)]
2025-09-03 05:44:39,828 - ==> Total time: 0:03:47	 Eta: 0:03:56 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:40,669 - Train: 49.07% [2650/5400]  [49.1/100.0] [batch_t 0.064 (0.080)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.159 (0.161)]
2025-09-03 05:44:43,890 - Train: 50.00% [2700/5400]  [50.0/100.0] [batch_t 0.063 (0.064)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.166 (0.161)]
2025-09-03 05:44:43,891 - ==> Total time: 0:03:51	 Eta: 0:03:51 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:47,662 - Train: 50.93% [2750/5400]  [50.9/100.0] [batch_t 0.064 (0.066)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.166 (0.160)]
2025-09-03 05:44:47,921 - ==> Total time: 0:03:55	 Eta: 0:03:45 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:51,402 - Train: 51.85% [2800/5400]  [51.9/100.0] [batch_t 0.064 (0.066)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.151 (0.159)]
2025-09-03 05:44:51,910 - ==> Total time: 0:03:59	 Eta: 0:03:40 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:55,169 - Train: 52.78% [2850/5400]  [52.8/100.0] [batch_t 0.064 (0.066)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.165 (0.158)]
2025-09-03 05:44:55,928 - ==> Total time: 0:04:03	 Eta: 0:03:35 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:44:58,873 - Train: 53.70% [2900/5400]  [53.7/100.0] [batch_t 0.062 (0.066)] [data_t 0.002] [optim_t 0.060] [lr 0.000050] [cos 0.163 (0.159)]
2025-09-03 05:44:59,892 - ==> Total time: 0:04:07	 Eta: 0:03:30 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:02,612 - Train: 54.63% [2950/5400]  [54.6/100.0] [batch_t 0.062 (0.065)] [data_t 0.002] [optim_t 0.060] [lr 0.000050] [cos 0.156 (0.158)]
2025-09-03 05:45:03,889 - ==> Total time: 0:04:11	 Eta: 0:03:25 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:06,340 - Train: 55.56% [3000/5400]  [55.6/100.0] [batch_t 0.064 (0.067)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.154 (0.157)]
2025-09-03 05:45:07,884 - ==> Total time: 0:04:15	 Eta: 0:03:20 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:10,101 - Train: 56.48% [3050/5400]  [56.5/100.0] [batch_t 0.065 (0.068)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.164 (0.155)]
2025-09-03 05:45:11,887 - ==> Total time: 0:04:19	 Eta: 0:03:15 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:13,848 - Train: 57.41% [3100/5400]  [57.4/100.0] [batch_t 0.064 (0.069)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.160 (0.153)]
2025-09-03 05:45:15,897 - ==> Total time: 0:04:23	 Eta: 0:03:10 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:17,662 - Train: 58.33% [3150/5400]  [58.3/100.0] [batch_t 0.065 (0.070)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.152 (0.153)]
2025-09-03 05:45:19,984 - ==> Total time: 0:04:27	 Eta: 0:03:05 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:21,468 - Train: 59.26% [3200/5400]  [59.3/100.0] [batch_t 0.064 (0.068)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.150 (0.149)]
2025-09-03 05:45:24,025 - ==> Total time: 0:04:31	 Eta: 0:03:00 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:25,281 - Train: 60.19% [3250/5400]  [60.2/100.0] [batch_t 0.064 (0.074)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.160 (0.151)]
2025-09-03 05:45:28,111 - ==> Total time: 0:04:35	 Eta: 0:02:56 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:29,060 - Train: 61.11% [3300/5400]  [61.1/100.0] [batch_t 0.063 (0.077)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.150 (0.149)]
2025-09-03 05:45:32,135 - ==> Total time: 0:04:39	 Eta: 0:02:51 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:32,832 - Train: 62.04% [3350/5400]  [62.0/100.0] [batch_t 0.064 (0.100)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.147 (0.152)]
2025-09-03 05:45:36,061 - Train: 62.96% [3400/5400]  [63.0/100.0] [batch_t 0.063 (0.065)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.145 (0.150)]
2025-09-03 05:45:36,192 - ==> Total time: 0:04:43	 Eta: 0:02:46 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:39,814 - Train: 63.89% [3450/5400]  [63.9/100.0] [batch_t 0.064 (0.066)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.149 (0.149)]
2025-09-03 05:45:40,195 - ==> Total time: 0:04:47	 Eta: 0:02:41 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:43,561 - Train: 64.81% [3500/5400]  [64.8/100.0] [batch_t 0.063 (0.066)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.144 (0.150)]
2025-09-03 05:45:44,207 - ==> Total time: 0:04:51	 Eta: 0:02:36 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:47,311 - Train: 65.74% [3550/5400]  [65.7/100.0] [batch_t 0.062 (0.066)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.147 (0.149)]
2025-09-03 05:45:48,202 - ==> Total time: 0:04:55	 Eta: 0:02:32 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:51,062 - Train: 66.67% [3600/5400]  [66.7/100.0] [batch_t 0.065 (0.067)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.149 (0.147)]
2025-09-03 05:45:52,220 - ==> Total time: 0:04:59	 Eta: 0:02:27 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:54,809 - Train: 67.59% [3650/5400]  [67.6/100.0] [batch_t 0.064 (0.065)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.134 (0.146)]
2025-09-03 05:45:56,216 - ==> Total time: 0:05:03	 Eta: 0:02:22 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:45:58,581 - Train: 68.52% [3700/5400]  [68.5/100.0] [batch_t 0.067 (0.069)] [data_t 0.002] [optim_t 0.065] [lr 0.000050] [cos 0.154 (0.147)]
2025-09-03 05:46:00,251 - ==> Total time: 0:05:07	 Eta: 0:02:18 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:02,366 - Train: 69.44% [3750/5400]  [69.4/100.0] [batch_t 0.066 (0.069)] [data_t 0.002] [optim_t 0.064] [lr 0.000050] [cos 0.157 (0.148)]
2025-09-03 05:46:04,286 - ==> Total time: 0:05:11	 Eta: 0:02:13 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:06,126 - Train: 70.37% [3800/5400]  [70.4/100.0] [batch_t 0.068 (0.067)] [data_t 0.002] [optim_t 0.066] [lr 0.000050] [cos 0.143 (0.147)]
2025-09-03 05:46:08,305 - ==> Total time: 0:05:15	 Eta: 0:02:08 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:09,908 - Train: 71.30% [3850/5400]  [71.3/100.0] [batch_t 0.063 (0.068)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.144 (0.146)]
2025-09-03 05:46:12,345 - ==> Total time: 0:05:19	 Eta: 0:02:04 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:13,672 - Train: 72.22% [3900/5400]  [72.2/100.0] [batch_t 0.064 (0.070)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.134 (0.143)]
2025-09-03 05:46:16,377 - ==> Total time: 0:05:23	 Eta: 0:01:59 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:17,422 - Train: 73.15% [3950/5400]  [73.1/100.0] [batch_t 0.065 (0.075)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.151 (0.146)]
2025-09-03 05:46:20,388 - ==> Total time: 0:05:27	 Eta: 0:01:55 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:21,173 - Train: 74.07% [4000/5400]  [74.1/100.0] [batch_t 0.064 (0.083)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.133 (0.138)]
2025-09-03 05:46:24,417 - Train: 75.00% [4050/5400]  [75.0/100.0] [batch_t 0.063 (0.065)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.153 (0.142)]
2025-09-03 05:46:24,418 - ==> Total time: 0:05:31	 Eta: 0:01:50 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:28,188 - Train: 75.93% [4100/5400]  [75.9/100.0] [batch_t 0.062 (0.066)] [data_t 0.002] [optim_t 0.060] [lr 0.000050] [cos 0.149 (0.142)]
2025-09-03 05:46:28,442 - ==> Total time: 0:05:35	 Eta: 0:01:45 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:31,949 - Train: 76.85% [4150/5400]  [76.9/100.0] [batch_t 0.062 (0.066)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.141 (0.141)]
2025-09-03 05:46:32,464 - ==> Total time: 0:05:39	 Eta: 0:01:41 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:35,736 - Train: 77.78% [4200/5400]  [77.8/100.0] [batch_t 0.063 (0.067)] [data_t 0.002] [optim_t 0.062] [lr 0.000050] [cos 0.151 (0.141)]
2025-09-03 05:46:36,510 - ==> Total time: 0:05:43	 Eta: 0:01:36 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:39,529 - Train: 78.70% [4250/5400]  [78.7/100.0] [batch_t 0.064 (0.067)] [data_t 0.002] [optim_t 0.063] [lr 0.000050] [cos 0.131 (0.140)]
2025-09-03 05:46:40,547 - ==> Total time: 0:05:47	 Eta: 0:01:32 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:43,219 - Train: 79.63% [4300/5400]  [79.6/100.0] [batch_t 0.063 (0.065)] [data_t 0.002] [optim_t 0.061] [lr 0.000050] [cos 0.143 (0.141)]
2025-09-03 05:46:44,498 - ==> Total time: 0:05:51	 Eta: 0:01:27 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:46,945 - Train: 80.56% [4350/5400]  [80.6/100.0] [batch_t 0.065 (0.065)] [data_t 0.002] [optim_t 0.064] [lr 0.000005] [cos 0.148 (0.139)]
2025-09-03 05:46:48,481 - ==> Total time: 0:05:55	 Eta: 0:01:23 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:50,681 - Train: 81.48% [4400/5400]  [81.5/100.0] [batch_t 0.064 (0.067)] [data_t 0.002] [optim_t 0.062] [lr 0.000005] [cos 0.128 (0.138)]
2025-09-03 05:46:52,486 - ==> Total time: 0:05:59	 Eta: 0:01:18 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:54,464 - Train: 82.41% [4450/5400]  [82.4/100.0] [batch_t 0.065 (0.069)] [data_t 0.002] [optim_t 0.063] [lr 0.000005] [cos 0.139 (0.136)]
2025-09-03 05:46:56,525 - ==> Total time: 0:06:03	 Eta: 0:01:14 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:46:58,269 - Train: 83.33% [4500/5400]  [83.3/100.0] [batch_t 0.063 (0.069)] [data_t 0.002] [optim_t 0.062] [lr 0.000005] [cos 0.135 (0.137)]
2025-09-03 05:47:00,575 - ==> Total time: 0:06:07	 Eta: 0:01:10 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:02,085 - Train: 84.26% [4550/5400]  [84.3/100.0] [batch_t 0.065 (0.073)] [data_t 0.002] [optim_t 0.063] [lr 0.000005] [cos 0.130 (0.137)]
2025-09-03 05:47:04,669 - ==> Total time: 0:06:11	 Eta: 0:01:05 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:05,881 - Train: 85.19% [4600/5400]  [85.2/100.0] [batch_t 0.063 (0.070)] [data_t 0.002] [optim_t 0.062] [lr 0.000005] [cos 0.141 (0.138)]
2025-09-03 05:47:08,700 - ==> Total time: 0:06:15	 Eta: 0:01:01 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:09,634 - Train: 86.11% [4650/5400]  [86.1/100.0] [batch_t 0.067 (0.082)] [data_t 0.002] [optim_t 0.065] [lr 0.000005] [cos 0.139 (0.140)]
2025-09-03 05:47:12,991 - ==> Total time: 0:06:20	 Eta: 0:00:56 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:13,713 - Train: 87.04% [4700/5400]  [87.0/100.0] [batch_t 0.064 (0.095)] [data_t 0.002] [optim_t 0.062] [lr 0.000005] [cos 0.147 (0.142)]
2025-09-03 05:47:16,931 - Train: 87.96% [4750/5400]  [88.0/100.0] [batch_t 0.067 (0.064)] [data_t 0.002] [optim_t 0.065] [lr 0.000005] [cos 0.139 (0.137)]
2025-09-03 05:47:17,060 - ==> Total time: 0:06:24	 Eta: 0:00:52 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:20,735 - Train: 88.89% [4800/5400]  [88.9/100.0] [batch_t 0.066 (0.066)] [data_t 0.002] [optim_t 0.065] [lr 0.000005] [cos 0.140 (0.137)]
2025-09-03 05:47:21,120 - ==> Total time: 0:06:28	 Eta: 0:00:47 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:24,510 - Train: 89.81% [4850/5400]  [89.8/100.0] [batch_t 0.068 (0.066)] [data_t 0.002] [optim_t 0.066] [lr 0.000005] [cos 0.132 (0.137)]
2025-09-03 05:47:25,148 - ==> Total time: 0:06:32	 Eta: 0:00:43 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:28,276 - Train: 90.74% [4900/5400]  [90.7/100.0] [batch_t 0.063 (0.066)] [data_t 0.002] [optim_t 0.061] [lr 0.000005] [cos 0.146 (0.137)]
2025-09-03 05:47:29,171 - ==> Total time: 0:06:36	 Eta: 0:00:39 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:32,025 - Train: 91.67% [4950/5400]  [91.7/100.0] [batch_t 0.065 (0.066)] [data_t 0.002] [optim_t 0.063] [lr 0.000005] [cos 0.141 (0.138)]
2025-09-03 05:47:33,179 - ==> Total time: 0:06:40	 Eta: 0:00:34 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:35,796 - Train: 92.59% [5000/5400]  [92.6/100.0] [batch_t 0.065 (0.067)] [data_t 0.002] [optim_t 0.063] [lr 0.000005] [cos 0.139 (0.136)]
2025-09-03 05:47:37,196 - ==> Total time: 0:06:44	 Eta: 0:00:30 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:39,579 - Train: 93.52% [5050/5400]  [93.5/100.0] [batch_t 0.063 (0.067)] [data_t 0.002] [optim_t 0.062] [lr 0.000005] [cos 0.146 (0.138)]
2025-09-03 05:47:41,248 - ==> Total time: 0:06:48	 Eta: 0:00:26 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:43,367 - Train: 94.44% [5100/5400]  [94.4/100.0] [batch_t 0.064 (0.068)] [data_t 0.002] [optim_t 0.062] [lr 0.000005] [cos 0.124 (0.136)]
2025-09-03 05:47:45,299 - ==> Total time: 0:06:52	 Eta: 0:00:21 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:47,154 - Train: 95.37% [5150/5400]  [95.4/100.0] [batch_t 0.064 (0.065)] [data_t 0.002] [optim_t 0.063] [lr 0.000005] [cos 0.147 (0.137)]
2025-09-03 05:47:49,348 - ==> Total time: 0:06:56	 Eta: 0:00:17 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:50,953 - Train: 96.30% [5200/5400]  [96.3/100.0] [batch_t 0.062 (0.069)] [data_t 0.002] [optim_t 0.060] [lr 0.000005] [cos 0.147 (0.136)]
2025-09-03 05:47:53,383 - ==> Total time: 0:07:00	 Eta: 0:00:13 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:54,692 - Train: 97.22% [5250/5400]  [97.2/100.0] [batch_t 0.068 (0.072)] [data_t 0.002] [optim_t 0.066] [lr 0.000005] [cos 0.124 (0.137)]
2025-09-03 05:47:57,393 - ==> Total time: 0:07:04	 Eta: 0:00:08 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:47:58,468 - Train: 98.15% [5300/5400]  [98.1/100.0] [batch_t 0.066 (0.069)] [data_t 0.002] [optim_t 0.065] [lr 0.000005] [cos 0.141 (0.138)]
2025-09-03 05:48:01,418 - ==> Total time: 0:07:08	 Eta: 0:00:04 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:48:02,233 - Train: 99.07% [5350/5400]  [99.1/100.0] [batch_t 0.066 (0.076)] [data_t 0.002] [optim_t 0.064] [lr 0.000005] [cos 0.143 (0.142)]
2025-09-03 05:48:05,439 - Train: 100.00% [5400/5400]  [100.0/100.0] [batch_t 0.061 (0.064)] [data_t 0.002] [optim_t 0.059] [lr 0.000005] [cos 0.135 (0.136)]
2025-09-03 05:48:09,212 - Test: 25.51% [50/196] [batch_t 0.068 (0.071)] [cos 0.237 (0.232)]
2025-09-03 05:48:12,610 - Test: 51.02% [100/196] [batch_t 0.067 (0.069)] [cos 0.241 (0.232)]
2025-09-03 05:48:15,994 - Test: 76.53% [150/196] [batch_t 0.068 (0.069)] [cos 0.133 (0.228)]
2025-09-03 05:48:19,284 - Test: 100.00% [196/196] [batch_t 0.301 (0.069)] [cos 0.179 (0.210)]
2025-09-03 05:48:55,532 - ==> Metric Time for wooden_beads   :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.002 (mAUROC_sp_max)	  0.001 (mAP_sp_max)	  0.001 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  9.647 (mF1_max_px)	  0.000 (mAUPRO_px)	  9.655 (mIoU_max_px)	
2025-09-03 05:48:55,563 - 
|     Name     |  S_AUROC  |   S_AUROC (Max)    |  S_AUPR  |    S_AUPR (Max)    |  mAUROC_sp_max  |  mAUROC_sp_max (Max)  |  mAP_sp_max  |  mAP_sp_max (Max)  |  mF1_max_sp_max  |  mF1_max_sp_max (Max)  |  mAUROC_px  |  mAUROC_px (Max)   |  mAP_px  |   mAP_px (Max)    |  mF1_max_px  |  mF1_max_px (Max)  |  mAUPRO_px  |  mAUPRO_px (Max)   |  mIoU_max_px  |  mIoU_max_px (Max)  |
|:------------:|:---------:|:------------------:|:--------:|:------------------:|:---------------:|:---------------------:|:------------:|:------------------:|:----------------:|:----------------------:|:-----------:|:------------------:|:--------:|:-----------------:|:------------:|:------------------:|:-----------:|:------------------:|:-------------:|:-------------------:|
| wooden_beads |  89.871   | 89.871 (100 epoch) |  95.862  | 95.862 (100 epoch) |     81.894      |  81.894 (100 epoch)   |    77.328    | 77.328 (100 epoch) |      72.092      |   72.092 (100 epoch)   |   95.767    | 95.767 (100 epoch) |  9.715   | 9.715 (100 epoch) |    15.761    | 15.761 (100 epoch) |   80.878    | 80.878 (100 epoch) |     8.555     |  8.555 (100 epoch)  |
2025-09-03 05:48:55,607 - ==> Total time: 0:08:02	 Eta: 0:00:00 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-054052'
2025-09-03 05:48:56,091 - finish training
