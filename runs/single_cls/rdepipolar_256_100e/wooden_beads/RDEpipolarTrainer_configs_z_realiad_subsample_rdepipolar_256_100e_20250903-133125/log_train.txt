2025-09-03 13:31:25,567 - ==> Logging on master GPU: 0
2025-09-03 13:31:25,567 - ==> Running Trainer: RDEpipolarTrainer
2025-09-03 13:31:25,568 - ==> Using GPU: [0] for Training
2025-09-03 13:31:25,568 - ==> Building model
2025-09-03 13:31:25,746 - Loading pretrained weights from url (https://download.pytorch.org/models/resnet18-5c106cde.pth)
2025-09-03 13:31:26,611 - 
------------------------------------ RDEpipolar ------------------------------------
| module                                             | #parameters or shape   | #flops       |
|:---------------------------------------------------|:-----------------------|:-------------|
| model                                              | 31.561M                | 5.207G       |
|  net_t                                             |  2.783M                |  1.838G      |
|   net_t.conv1                                      |   9.408K               |   0.154G     |
|    net_t.conv1.weight                              |    (64, 3, 7, 7)       |              |
|   net_t.bn1                                        |   0.128K               |   2.097M     |
|    net_t.bn1.weight                                |    (64,)               |              |
|    net_t.bn1.bias                                  |    (64,)               |              |
|   net_t.layer1                                     |   0.148M               |   0.606G     |
|    net_t.layer1.0                                  |    73.984K             |    0.303G    |
|     net_t.layer1.0.conv1                           |     36.864K            |     0.151G   |
|      net_t.layer1.0.conv1.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.0.bn1                             |     0.128K             |     0.524M   |
|      net_t.layer1.0.bn1.weight                     |      (64,)             |              |
|      net_t.layer1.0.bn1.bias                       |      (64,)             |              |
|     net_t.layer1.0.conv2                           |     36.864K            |     0.151G   |
|      net_t.layer1.0.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.0.bn2                             |     0.128K             |     0.524M   |
|      net_t.layer1.0.bn2.weight                     |      (64,)             |              |
|      net_t.layer1.0.bn2.bias                       |      (64,)             |              |
|    net_t.layer1.1                                  |    73.984K             |    0.303G    |
|     net_t.layer1.1.conv1                           |     36.864K            |     0.151G   |
|      net_t.layer1.1.conv1.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.1.bn1                             |     0.128K             |     0.524M   |
|      net_t.layer1.1.bn1.weight                     |      (64,)             |              |
|      net_t.layer1.1.bn1.bias                       |      (64,)             |              |
|     net_t.layer1.1.conv2                           |     36.864K            |     0.151G   |
|      net_t.layer1.1.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_t.layer1.1.bn2                             |     0.128K             |     0.524M   |
|      net_t.layer1.1.bn2.weight                     |      (64,)             |              |
|      net_t.layer1.1.bn2.bias                       |      (64,)             |              |
|   net_t.layer2                                     |   0.526M               |   0.538G     |
|    net_t.layer2.0                                  |    0.23M               |    0.236G    |
|     net_t.layer2.0.conv1                           |     73.728K            |     75.497M  |
|      net_t.layer2.0.conv1.weight                   |      (128, 64, 3, 3)   |              |
|     net_t.layer2.0.bn1                             |     0.256K             |     0.262M   |
|      net_t.layer2.0.bn1.weight                     |      (128,)            |              |
|      net_t.layer2.0.bn1.bias                       |      (128,)            |              |
|     net_t.layer2.0.conv2                           |     0.147M             |     0.151G   |
|      net_t.layer2.0.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_t.layer2.0.bn2                             |     0.256K             |     0.262M   |
|      net_t.layer2.0.bn2.weight                     |      (128,)            |              |
|      net_t.layer2.0.bn2.bias                       |      (128,)            |              |
|     net_t.layer2.0.downsample                      |     8.448K             |     8.651M   |
|      net_t.layer2.0.downsample.0                   |      8.192K            |      8.389M  |
|      net_t.layer2.0.downsample.1                   |      0.256K            |      0.262M  |
|    net_t.layer2.1                                  |    0.295M              |    0.303G    |
|     net_t.layer2.1.conv1                           |     0.147M             |     0.151G   |
|      net_t.layer2.1.conv1.weight                   |      (128, 128, 3, 3)  |              |
|     net_t.layer2.1.bn1                             |     0.256K             |     0.262M   |
|      net_t.layer2.1.bn1.weight                     |      (128,)            |              |
|      net_t.layer2.1.bn1.bias                       |      (128,)            |              |
|     net_t.layer2.1.conv2                           |     0.147M             |     0.151G   |
|      net_t.layer2.1.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_t.layer2.1.bn2                             |     0.256K             |     0.262M   |
|      net_t.layer2.1.bn2.weight                     |      (128,)            |              |
|      net_t.layer2.1.bn2.bias                       |      (128,)            |              |
|   net_t.layer3                                     |   2.1M                 |   0.538G     |
|    net_t.layer3.0                                  |    0.919M              |    0.235G    |
|     net_t.layer3.0.conv1                           |     0.295M             |     75.497M  |
|      net_t.layer3.0.conv1.weight                   |      (256, 128, 3, 3)  |              |
|     net_t.layer3.0.bn1                             |     0.512K             |     0.131M   |
|      net_t.layer3.0.bn1.weight                     |      (256,)            |              |
|      net_t.layer3.0.bn1.bias                       |      (256,)            |              |
|     net_t.layer3.0.conv2                           |     0.59M              |     0.151G   |
|      net_t.layer3.0.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_t.layer3.0.bn2                             |     0.512K             |     0.131M   |
|      net_t.layer3.0.bn2.weight                     |      (256,)            |              |
|      net_t.layer3.0.bn2.bias                       |      (256,)            |              |
|     net_t.layer3.0.downsample                      |     33.28K             |     8.52M    |
|      net_t.layer3.0.downsample.0                   |      32.768K           |      8.389M  |
|      net_t.layer3.0.downsample.1                   |      0.512K            |      0.131M  |
|    net_t.layer3.1                                  |    1.181M              |    0.302G    |
|     net_t.layer3.1.conv1                           |     0.59M              |     0.151G   |
|      net_t.layer3.1.conv1.weight                   |      (256, 256, 3, 3)  |              |
|     net_t.layer3.1.bn1                             |     0.512K             |     0.131M   |
|      net_t.layer3.1.bn1.weight                     |      (256,)            |              |
|      net_t.layer3.1.bn1.bias                       |      (256,)            |              |
|     net_t.layer3.1.conv2                           |     0.59M              |     0.151G   |
|      net_t.layer3.1.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_t.layer3.1.bn2                             |     0.512K             |     0.131M   |
|      net_t.layer3.1.bn2.weight                     |      (256,)            |              |
|      net_t.layer3.1.bn2.bias                       |      (256,)            |              |
|  mff_oce                                           |  16.401M               |  1.234G      |
|   mff_oce.bn_layer                                 |   15.736M              |   1.007G     |
|    mff_oce.bn_layer.0                              |    6.295M              |    0.403G    |
|     mff_oce.bn_layer.0.conv1                       |     3.539M             |     0.226G   |
|      mff_oce.bn_layer.0.conv1.weight               |      (512, 768, 3, 3)  |              |
|     mff_oce.bn_layer.0.bn1                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.0.bn1.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.0.bn1.bias                   |      (512,)            |              |
|     mff_oce.bn_layer.0.conv2                       |     2.359M             |     0.151G   |
|      mff_oce.bn_layer.0.conv2.weight               |      (512, 512, 3, 3)  |              |
|     mff_oce.bn_layer.0.bn2                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.0.bn2.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.0.bn2.bias                   |      (512,)            |              |
|     mff_oce.bn_layer.0.downsample                  |     0.394M             |     25.231M  |
|      mff_oce.bn_layer.0.downsample.0               |      0.393M            |      25.166M |
|      mff_oce.bn_layer.0.downsample.1               |      1.024K            |      65.536K |
|    mff_oce.bn_layer.1                              |    4.721M              |    0.302G    |
|     mff_oce.bn_layer.1.conv1                       |     2.359M             |     0.151G   |
|      mff_oce.bn_layer.1.conv1.weight               |      (512, 512, 3, 3)  |              |
|     mff_oce.bn_layer.1.bn1                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.1.bn1.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.1.bn1.bias                   |      (512,)            |              |
|     mff_oce.bn_layer.1.conv2                       |     2.359M             |     0.151G   |
|      mff_oce.bn_layer.1.conv2.weight               |      (512, 512, 3, 3)  |              |
|     mff_oce.bn_layer.1.bn2                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.1.bn2.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.1.bn2.bias                   |      (512,)            |              |
|    mff_oce.bn_layer.2                              |    4.721M              |    0.302G    |
|     mff_oce.bn_layer.2.conv1                       |     2.359M             |     0.151G   |
|      mff_oce.bn_layer.2.conv1.weight               |      (512, 512, 3, 3)  |              |
|     mff_oce.bn_layer.2.bn1                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.2.bn1.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.2.bn1.bias                   |      (512,)            |              |
|     mff_oce.bn_layer.2.conv2                       |     2.359M             |     0.151G   |
|      mff_oce.bn_layer.2.conv2.weight               |      (512, 512, 3, 3)  |              |
|     mff_oce.bn_layer.2.bn2                         |     1.024K             |     65.536K  |
|      mff_oce.bn_layer.2.bn2.weight                 |      (512,)            |              |
|      mff_oce.bn_layer.2.bn2.bias                   |      (512,)            |              |
|   mff_oce.conv1                                    |   73.728K              |   75.497M    |
|    mff_oce.conv1.weight                            |    (128, 64, 3, 3)     |              |
|   mff_oce.bn1                                      |   0.256K               |   0.262M     |
|    mff_oce.bn1.weight                              |    (128,)              |              |
|    mff_oce.bn1.bias                                |    (128,)              |              |
|   mff_oce.conv2                                    |   0.295M               |   75.497M    |
|    mff_oce.conv2.weight                            |    (256, 128, 3, 3)    |              |
|   mff_oce.bn2                                      |   0.512K               |   0.131M     |
|    mff_oce.bn2.weight                              |    (256,)              |              |
|    mff_oce.bn2.bias                                |    (256,)              |              |
|   mff_oce.conv3                                    |   0.295M               |   75.497M    |
|    mff_oce.conv3.weight                            |    (256, 128, 3, 3)    |              |
|   mff_oce.bn3                                      |   0.512K               |   0.131M     |
|    mff_oce.bn3.weight                              |    (256,)              |              |
|    mff_oce.bn3.bias                                |    (256,)              |              |
|  net_s                                             |  3.703M                |  1.565G      |
|   net_s.layer1                                     |   2.821M               |   0.521G     |
|    net_s.layer1.0                                  |    1.64M               |    0.218G    |
|     net_s.layer1.0.conv1                           |     0.524M             |     33.554M  |
|      net_s.layer1.0.conv1.weight                   |      (512, 256, 2, 2)  |              |
|     net_s.layer1.0.bn1                             |     0.512K             |     0.131M   |
|      net_s.layer1.0.bn1.weight                     |      (256,)            |              |
|      net_s.layer1.0.bn1.bias                       |      (256,)            |              |
|     net_s.layer1.0.conv2                           |     0.59M              |     0.151G   |
|      net_s.layer1.0.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_s.layer1.0.bn2                             |     0.512K             |     0.131M   |
|      net_s.layer1.0.bn2.weight                     |      (256,)            |              |
|      net_s.layer1.0.bn2.bias                       |      (256,)            |              |
|     net_s.layer1.0.upsample                        |     0.525M             |     33.686M  |
|      net_s.layer1.0.upsample.0                     |      0.524M            |      33.554M |
|      net_s.layer1.0.upsample.1                     |      0.512K            |      0.131M  |
|    net_s.layer1.1                                  |    1.181M              |    0.302G    |
|     net_s.layer1.1.conv1                           |     0.59M              |     0.151G   |
|      net_s.layer1.1.conv1.weight                   |      (256, 256, 3, 3)  |              |
|     net_s.layer1.1.bn1                             |     0.512K             |     0.131M   |
|      net_s.layer1.1.bn1.weight                     |      (256,)            |              |
|      net_s.layer1.1.bn1.bias                       |      (256,)            |              |
|     net_s.layer1.1.conv2                           |     0.59M              |     0.151G   |
|      net_s.layer1.1.conv2.weight                   |      (256, 256, 3, 3)  |              |
|     net_s.layer1.1.bn2                             |     0.512K             |     0.131M   |
|      net_s.layer1.1.bn2.weight                     |      (256,)            |              |
|      net_s.layer1.1.bn2.bias                       |      (256,)            |              |
|   net_s.layer2                                     |   0.706M               |   0.521G     |
|    net_s.layer2.0                                  |    0.41M               |    0.219G    |
|     net_s.layer2.0.conv1                           |     0.131M             |     33.554M  |
|      net_s.layer2.0.conv1.weight                   |      (256, 128, 2, 2)  |              |
|     net_s.layer2.0.bn1                             |     0.256K             |     0.262M   |
|      net_s.layer2.0.bn1.weight                     |      (128,)            |              |
|      net_s.layer2.0.bn1.bias                       |      (128,)            |              |
|     net_s.layer2.0.conv2                           |     0.147M             |     0.151G   |
|      net_s.layer2.0.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_s.layer2.0.bn2                             |     0.256K             |     0.262M   |
|      net_s.layer2.0.bn2.weight                     |      (128,)            |              |
|      net_s.layer2.0.bn2.bias                       |      (128,)            |              |
|     net_s.layer2.0.upsample                        |     0.131M             |     33.817M  |
|      net_s.layer2.0.upsample.0                     |      0.131M            |      33.554M |
|      net_s.layer2.0.upsample.1                     |      0.256K            |      0.262M  |
|    net_s.layer2.1                                  |    0.295M              |    0.303G    |
|     net_s.layer2.1.conv1                           |     0.147M             |     0.151G   |
|      net_s.layer2.1.conv1.weight                   |      (128, 128, 3, 3)  |              |
|     net_s.layer2.1.bn1                             |     0.256K             |     0.262M   |
|      net_s.layer2.1.bn1.weight                     |      (128,)            |              |
|      net_s.layer2.1.bn1.bias                       |      (128,)            |              |
|     net_s.layer2.1.conv2                           |     0.147M             |     0.151G   |
|      net_s.layer2.1.conv2.weight                   |      (128, 128, 3, 3)  |              |
|     net_s.layer2.1.bn2                             |     0.256K             |     0.262M   |
|      net_s.layer2.1.bn2.weight                     |      (128,)            |              |
|      net_s.layer2.1.bn2.bias                       |      (128,)            |              |
|   net_s.layer3                                     |   0.177M               |   0.523G     |
|    net_s.layer3.0                                  |    0.103M              |    0.22G     |
|     net_s.layer3.0.conv1                           |     32.768K            |     33.554M  |
|      net_s.layer3.0.conv1.weight                   |      (128, 64, 2, 2)   |              |
|     net_s.layer3.0.bn1                             |     0.128K             |     0.524M   |
|      net_s.layer3.0.bn1.weight                     |      (64,)             |              |
|      net_s.layer3.0.bn1.bias                       |      (64,)             |              |
|     net_s.layer3.0.conv2                           |     36.864K            |     0.151G   |
|      net_s.layer3.0.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_s.layer3.0.bn2                             |     0.128K             |     0.524M   |
|      net_s.layer3.0.bn2.weight                     |      (64,)             |              |
|      net_s.layer3.0.bn2.bias                       |      (64,)             |              |
|     net_s.layer3.0.upsample                        |     32.896K            |     34.079M  |
|      net_s.layer3.0.upsample.0                     |      32.768K           |      33.554M |
|      net_s.layer3.0.upsample.1                     |      0.128K            |      0.524M  |
|    net_s.layer3.1                                  |    73.984K             |    0.303G    |
|     net_s.layer3.1.conv1                           |     36.864K            |     0.151G   |
|      net_s.layer3.1.conv1.weight                   |      (64, 64, 3, 3)    |              |
|     net_s.layer3.1.bn1                             |     0.128K             |     0.524M   |
|      net_s.layer3.1.bn1.weight                     |      (64,)             |              |
|      net_s.layer3.1.bn1.bias                       |      (64,)             |              |
|     net_s.layer3.1.conv2                           |     36.864K            |     0.151G   |
|      net_s.layer3.1.conv2.weight                   |      (64, 64, 3, 3)    |              |
|     net_s.layer3.1.bn2                             |     0.128K             |     0.524M   |
|      net_s.layer3.1.bn2.weight                     |      (64,)             |              |
|      net_s.layer3.1.bn2.bias                       |      (64,)             |              |
|  proj_layer                                        |  0.969M                |  0.57G       |
|   proj_layer.proj_a.proj                           |   46.224K              |   0.191G     |
|    proj_layer.proj_a.proj.0                        |    18.464K             |    75.497M   |
|     proj_layer.proj_a.proj.0.weight                |     (32, 64, 3, 3)     |              |
|     proj_layer.proj_a.proj.0.bias                  |     (32,)              |              |
|    proj_layer.proj_a.proj.3                        |    4.624K              |    18.874M   |
|     proj_layer.proj_a.proj.3.weight                |     (16, 32, 3, 3)     |              |
|     proj_layer.proj_a.proj.3.bias                  |     (16,)              |              |
|    proj_layer.proj_a.proj.6                        |    4.64K               |    18.874M   |
|     proj_layer.proj_a.proj.6.weight                |     (32, 16, 3, 3)     |              |
|     proj_layer.proj_a.proj.6.bias                  |     (32,)              |              |
|    proj_layer.proj_a.proj.9                        |    18.496K             |    75.497M   |
|     proj_layer.proj_a.proj.9.weight                |     (64, 32, 3, 3)     |              |
|     proj_layer.proj_a.proj.9.bias                  |     (64,)              |              |
|    proj_layer.proj_a.proj.1                        |                        |    0.524M    |
|    proj_layer.proj_a.proj.4                        |                        |    0.262M    |
|    proj_layer.proj_a.proj.7                        |                        |    0.524M    |
|    proj_layer.proj_a.proj.10                       |                        |    1.049M    |
|   proj_layer.proj_b.proj                           |   0.185M               |   0.19G      |
|    proj_layer.proj_b.proj.0                        |    73.792K             |    75.497M   |
|     proj_layer.proj_b.proj.0.weight                |     (64, 128, 3, 3)    |              |
|     proj_layer.proj_b.proj.0.bias                  |     (64,)              |              |
|    proj_layer.proj_b.proj.3                        |    18.464K             |    18.874M   |
|     proj_layer.proj_b.proj.3.weight                |     (32, 64, 3, 3)     |              |
|     proj_layer.proj_b.proj.3.bias                  |     (32,)              |              |
|    proj_layer.proj_b.proj.6                        |    18.496K             |    18.874M   |
|     proj_layer.proj_b.proj.6.weight                |     (64, 32, 3, 3)     |              |
|     proj_layer.proj_b.proj.6.bias                  |     (64,)              |              |
|    proj_layer.proj_b.proj.9                        |    73.856K             |    75.497M   |
|     proj_layer.proj_b.proj.9.weight                |     (128, 64, 3, 3)    |              |
|     proj_layer.proj_b.proj.9.bias                  |     (128,)             |              |
|    proj_layer.proj_b.proj.1                        |                        |    0.262M    |
|    proj_layer.proj_b.proj.4                        |                        |    0.131M    |
|    proj_layer.proj_b.proj.7                        |                        |    0.262M    |
|    proj_layer.proj_b.proj.10                       |                        |    0.524M    |
|   proj_layer.proj_c.proj                           |   0.738M               |   0.189G     |
|    proj_layer.proj_c.proj.0                        |    0.295M              |    75.497M   |
|     proj_layer.proj_c.proj.0.weight                |     (128, 256, 3, 3)   |              |
|     proj_layer.proj_c.proj.0.bias                  |     (128,)             |              |
|    proj_layer.proj_c.proj.3                        |    73.792K             |    18.874M   |
|     proj_layer.proj_c.proj.3.weight                |     (64, 128, 3, 3)    |              |
|     proj_layer.proj_c.proj.3.bias                  |     (64,)              |              |
|    proj_layer.proj_c.proj.6                        |    73.856K             |    18.874M   |
|     proj_layer.proj_c.proj.6.weight                |     (128, 64, 3, 3)    |              |
|     proj_layer.proj_c.proj.6.bias                  |     (128,)             |              |
|    proj_layer.proj_c.proj.9                        |    0.295M              |    75.497M   |
|     proj_layer.proj_c.proj.9.weight                |     (256, 128, 3, 3)   |              |
|     proj_layer.proj_c.proj.9.bias                  |     (256,)             |              |
|    proj_layer.proj_c.proj.1                        |                        |    0.131M    |
|    proj_layer.proj_c.proj.4                        |                        |    65.536K   |
|    proj_layer.proj_c.proj.7                        |                        |    0.131M    |
|    proj_layer.proj_c.proj.10                       |                        |    0.262M    |
|  net_ad                                            |  7.706M                |              |
|   net_ad.pos_embed                                 |   2.048K               |              |
|    net_ad.pos_embed.row_embed                      |    1.024K              |              |
|     net_ad.pos_embed.row_embed.weight              |     (8, 128)           |              |
|    net_ad.pos_embed.col_embed                      |    1.024K              |              |
|     net_ad.pos_embed.col_embed.weight              |     (8, 128)           |              |
|   net_ad.transformer                               |   7.441M               |              |
|    net_ad.transformer.encoder.layers               |    3.161M              |              |
|     net_ad.transformer.encoder.layers.0            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.0.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.0.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.0.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.0.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.0.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.0.norm_mid  |      0.512K            |              |
|     net_ad.transformer.encoder.layers.1            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.1.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.1.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.1.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.1.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.1.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.1.norm_mid  |      0.512K            |              |
|     net_ad.transformer.encoder.layers.2            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.2.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.2.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.2.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.2.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.2.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.2.norm_mid  |      0.512K            |              |
|     net_ad.transformer.encoder.layers.3            |     0.79M              |              |
|      net_ad.transformer.encoder.layers.3.self_attn |      0.263M            |              |
|      net_ad.transformer.encoder.layers.3.linear1   |      0.263M            |              |
|      net_ad.transformer.encoder.layers.3.linear2   |      0.262M            |              |
|      net_ad.transformer.encoder.layers.3.norm1     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.3.norm2     |      0.512K            |              |
|      net_ad.transformer.encoder.layers.3.norm_mid  |      0.512K            |              |
|    net_ad.transformer.decoder                      |    4.28M               |              |
|     net_ad.transformer.decoder.layers              |     4.279M             |              |
|      net_ad.transformer.decoder.layers.0           |      1.07M             |              |
|      net_ad.transformer.decoder.layers.1           |      1.07M             |              |
|      net_ad.transformer.decoder.layers.2           |      1.07M             |              |
|      net_ad.transformer.decoder.layers.3           |      1.07M             |              |
|     net_ad.transformer.decoder.norm                |     0.512K             |              |
|      net_ad.transformer.decoder.norm.weight        |      (256,)            |              |
|      net_ad.transformer.decoder.norm.bias          |      (256,)            |              |
|   net_ad.input_proj                                |   0.131M               |              |
|    net_ad.input_proj.weight                        |    (256, 512)          |              |
|    net_ad.input_proj.bias                          |    (256,)              |              |
|   net_ad.output_proj                               |   0.132M               |              |
|    net_ad.output_proj.weight                       |    (512, 256)          |              |
|    net_ad.output_proj.bias                         |    (512,)              |              |
------------------------------------------------------------------------------------
2025-09-03 13:31:26,612 - ==> Creating optimizer
2025-09-03 13:31:26,613 - ==> Loading dataset: RealIAD
2025-09-03 13:31:26,624 - ==> ********** cfg ********** 
fvcore_is                            : True                                
fvcore_b                             : 1                                   
fvcore_c                             : 3                                   
epoch_full                           : 100                                 
metrics                              : ['S_AUROC', 'S_AUPR', 'mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mAUPRO_px', 'mIoU_max_px']
use_adeval                           : True                                
evaluator.kwargs                     : {'metrics': ['S_AUROC', 'S_AUPR', 'mAUROC_sp_max', 'mAP_sp_max', 'mF1_max_sp_max', 'mAUROC_px', 'mAP_px', 'mF1_max_px', 'mAUPRO_px', 'mIoU_max_px'], 'pooling_ks': [16, 16], 'max_step_aupro': 100, 'use_adeval': True}
optim.lr                             : 5e-05                               
optim.kwargs                         : {'name': 'adamw', 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0001, 'amsgrad': False}
trainer.name                         : RDEpipolarTrainer                   
trainer.checkpoint                   : runs/single_cls/rdepipolar_256_100e/wooden_beads
trainer.logdir_sub                   :                                     
trainer.resume_dir                   :                                     
trainer.cuda_deterministic           : False                               
trainer.epoch_full                   : 100                                 
trainer.scheduler_kwargs             : {'name': 'step', 'lr_noise': None, 'noise_pct': 0.67, 'noise_std': 1.0, 'noise_seed': 42, 'lr_min': 5e-07, 'warmup_lr': 5.0000000000000004e-08, 'warmup_iters': -1, 'cooldown_iters': 0, 'warmup_epochs': 0, 'cooldown_epochs': 0, 'use_iters': True, 'patience_iters': 0, 'patience_epochs': 0, 'decay_iters': 0, 'decay_epochs': 80, 'cycle_decay': 0.1, 'decay_rate': 0.1}
trainer.mixup_kwargs                 : {'mixup_alpha': 0.8, 'cutmix_alpha': 1.0, 'cutmix_minmax': None, 'prob': 0.0, 'switch_prob': 0.5, 'mode': 'batch', 'correct_lam': True, 'label_smoothing': 0.1}
trainer.test_start_epoch             : 100                                 
trainer.test_per_epoch               : 100                                 
trainer.find_unused_parameters       : False                               
trainer.sync_BN                      : apex                                
trainer.dist_BN                      :                                     
trainer.scaler                       : none                                
trainer.data.batch_size              : 4                                   
trainer.data.batch_size_per_gpu      : 4                                   
trainer.data.batch_size_test         : 4                                   
trainer.data.batch_size_per_gpu_test : 4                                   
trainer.data.num_workers_per_gpu     : 8                                   
trainer.data.drop_last               : True                                
trainer.data.pin_memory              : True                                
trainer.data.persistent_workers      : False                               
trainer.data.num_workers             : 8                                   
trainer.iter                         : 0                                   
trainer.epoch                        : 0                                   
trainer.iter_full                    : 5400                                
trainer.metric_recorder              : {'S_AUROC_wooden_beads': [], 'S_AUPR_wooden_beads': [], 'mAUROC_sp_max_wooden_beads': [], 'mAP_sp_max_wooden_beads': [], 'mF1_max_sp_max_wooden_beads': [], 'mAUROC_px_wooden_beads': [], 'mAP_px_wooden_beads': [], 'mF1_max_px_wooden_beads': [], 'mAUPRO_px_wooden_beads': [], 'mIoU_max_px_wooden_beads': []}
loss.loss_terms                      : [{'type': 'CosLoss', 'name': 'cos', 'avg': False, 'lam': 1.0}]
loss.clip_grad                       : 5.0                                 
loss.create_graph                    : False                               
loss.retain_graph                    : False                               
adv                                  : False                               
logging.log_terms_train              : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'data_t', 'fmt': ':>5.3f'}, {'name': 'optim_t', 'fmt': ':>5.3f'}, {'name': 'lr', 'fmt': ':>7.6f'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.log_terms_test               : [{'name': 'batch_t', 'fmt': ':>5.3f', 'add_name': 'avg'}, {'name': 'cos', 'suffixes': [''], 'fmt': ':>5.3f', 'add_name': 'avg'}]
logging.train_reset_log_per          : 50                                  
logging.train_log_per                : 50                                  
logging.test_log_per                 : 50                                  
data.sampler                         : naive                               
data.loader_type                     : pil                                 
data.loader_type_target              : pil_L                               
data.type                            : RealIAD                             
data.root                            : /home/albus/DataSets/REAL-IAD/realiad_256
data.meta                            : meta.json                           
data.cls_names                       : wooden_beads                        
data.train_transforms                : [{'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.test_transforms                 : [{'type': 'ToTensor'}, {'type': 'Normalize', 'mean': (0.485, 0.456, 0.406), 'std': (0.229, 0.224, 0.225), 'inplace': True}]
data.target_transforms               : [{'type': 'ToTensor'}]              
data.use_sample                      : True                                
data.views                           : []                                  
data.train_size                      : 54                                  
data.test_size                       : 196                                 
data.train_length                    : 218                                 
data.test_length                     : 783                                 
model_t.name                         : timm_resnet18                       
model_t.kwargs                       : {'pretrained': True, 'checkpoint_path': '', 'strict': False, 'features_only': True, 'out_indices': [1, 2, 3]}
model_s.name                         : de_resnet18                         
model_s.kwargs                       : {'pretrained': False, 'checkpoint_path': '', 'strict': False}
model.name                           : rdepipolar                          
model.kwargs                         : {'pretrained': False, 'checkpoint_path': '', 'strict': True, 'model_t': Namespace(kwargs={'pretrained': True, 'checkpoint_path': '', 'strict': False, 'features_only': True, 'out_indices': [1, 2, 3]}, name='timm_resnet18'), 'model_s': Namespace(kwargs={'pretrained': False, 'checkpoint_path': '', 'strict': False}, name='de_resnet18')}
seed                                 : 42                                  
size                                 : 256                                 
warmup_epochs                        : 0                                   
test_start_epoch                     : 100                                 
test_per_epoch                       : 100                                 
batch_train                          : 4                                   
batch_test_per                       : 4                                   
lr                                   : 5e-05                               
weight_decay                         : 0.0001                              
cfg_path                             : configs.z_realiad_subsample.rdepipolar_256_100e
mode                                 : train                               
sleep                                : -1                                  
memory                               : -1                                  
dist_url                             : env://                              
logger_rank                          : 0                                   
opts                                 : ['data.cls_names=wooden_beads', 'trainer.checkpoint=runs/single_cls/rdepipolar_256_100e/wooden_beads']
command                              : python3 -m torch.distributed.launch --nproc_per_node=$nproc_per_node --nnodes=$nnodes --node_rank=$node_rank --master_addr=$master_addr --master_port=$master_port --use_env run.py -c configs.z_realiad_subsample.rdepipolar_256_100e -m train --sleep -1 --memory -1 --dist_url env:// --logger_rank 0 data.cls_names=wooden_beads trainer.checkpoint=runs/single_cls/rdepipolar_256_100e/wooden_beads
task_start_time                      : 1898576.480067363                   
dist                                 : False                               
world_size                           : 1                                   
rank                                 : 0                                   
local_rank                           : 0                                   
ngpus_per_node                       : 1                                   
nnodes                               : 1                                   
master                               : True                                
logdir                               : runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125
logger.filters                       : []                                  
logger.name                          : root                                
logger.level                         : 20                                  
logger.parent                        : None                                
logger.propagate                     : True                                
logger.disabled                      : False                               
logdir_train                         : runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125/show_train
logdir_test                          : runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125/show_test
2025-09-03 13:31:26,624 - ==> Starting training with 1 nodes x 1 GPUs
2025-09-03 13:31:30,839 - Train: 0.93% [50/5400]  [0.9/100.0] [batch_t 0.054 (0.082)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 1.152 (1.485)]
2025-09-03 13:31:31,058 - ==> Total time: 0:00:05	 Eta: 0:09:03 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:31:33,974 - Train: 1.85% [100/5400]  [1.9/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.815 (0.939)]
2025-09-03 13:31:34,411 - ==> Total time: 0:00:08	 Eta: 0:07:13 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:31:37,223 - Train: 2.78% [150/5400]  [2.8/100.0] [batch_t 0.054 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.674 (0.728)]
2025-09-03 13:31:37,880 - ==> Total time: 0:00:12	 Eta: 0:06:38 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:31:40,475 - Train: 3.70% [200/5400]  [3.7/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.589 (0.622)]
2025-09-03 13:31:41,351 - ==> Total time: 0:00:15	 Eta: 0:06:18 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:31:43,631 - Train: 4.63% [250/5400]  [4.6/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.523 (0.549)]
2025-09-03 13:31:44,726 - ==> Total time: 0:00:19	 Eta: 0:06:04 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:31:46,816 - Train: 5.56% [300/5400]  [5.6/100.0] [batch_t 0.055 (0.059)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.472 (0.490)]
2025-09-03 13:31:48,131 - ==> Total time: 0:00:22	 Eta: 0:05:53 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:31:50,007 - Train: 6.48% [350/5400]  [6.5/100.0] [batch_t 0.055 (0.059)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.432 (0.448)]
2025-09-03 13:31:51,542 - ==> Total time: 0:00:25	 Eta: 0:05:45 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:31:53,521 - Train: 7.41% [400/5400]  [7.4/100.0] [batch_t 0.055 (0.072)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.414 (0.411)]
2025-09-03 13:31:55,277 - ==> Total time: 0:00:29	 Eta: 0:05:41 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:31:56,776 - Train: 8.33% [450/5400]  [8.3/100.0] [batch_t 0.055 (0.061)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.391 (0.384)]
2025-09-03 13:31:58,750 - ==> Total time: 0:00:33	 Eta: 0:05:35 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:00,012 - Train: 9.26% [500/5400]  [9.3/100.0] [batch_t 0.056 (0.063)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.341 (0.356)]
2025-09-03 13:32:02,207 - ==> Total time: 0:00:36	 Eta: 0:05:29 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:03,184 - Train: 10.19% [550/5400]  [10.2/100.0] [batch_t 0.055 (0.064)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.338 (0.344)]
2025-09-03 13:32:05,599 - ==> Total time: 0:00:40	 Eta: 0:05:23 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:06,374 - Train: 11.11% [600/5400]  [11.1/100.0] [batch_t 0.057 (0.073)] [data_t 0.002] [optim_t 0.055] [lr 0.000050] [cos 0.307 (0.320)]
2025-09-03 13:32:09,015 - ==> Total time: 0:00:43	 Eta: 0:05:18 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:09,551 - Train: 12.04% [650/5400]  [12.0/100.0] [batch_t 0.060 (0.102)] [data_t 0.002] [optim_t 0.058] [lr 0.000050] [cos 0.301 (0.295)]
2025-09-03 13:32:12,315 - Train: 12.96% [700/5400]  [13.0/100.0] [batch_t 0.055 (0.055)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.300 (0.296)]
2025-09-03 13:32:12,426 - ==> Total time: 0:00:46	 Eta: 0:05:13 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:15,532 - Train: 13.89% [750/5400]  [13.9/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.275 (0.284)]
2025-09-03 13:32:15,863 - ==> Total time: 0:00:50	 Eta: 0:05:08 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:18,749 - Train: 14.81% [800/5400]  [14.8/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.281 (0.274)]
2025-09-03 13:32:19,301 - ==> Total time: 0:00:53	 Eta: 0:05:04 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:21,996 - Train: 15.74% [850/5400]  [15.7/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.261 (0.265)]
2025-09-03 13:32:22,767 - ==> Total time: 0:00:57	 Eta: 0:05:00 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:25,256 - Train: 16.67% [900/5400]  [16.7/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.267 (0.253)]
2025-09-03 13:32:26,247 - ==> Total time: 0:01:00	 Eta: 0:04:56 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:28,484 - Train: 17.59% [950/5400]  [17.6/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.241 (0.247)]
2025-09-03 13:32:29,696 - ==> Total time: 0:01:04	 Eta: 0:04:52 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:31,688 - Train: 18.52% [1000/5400]  [18.5/100.0] [batch_t 0.055 (0.059)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.233 (0.241)]
2025-09-03 13:32:33,122 - ==> Total time: 0:01:07	 Eta: 0:04:47 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:34,908 - Train: 19.44% [1050/5400]  [19.4/100.0] [batch_t 0.055 (0.060)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.221 (0.232)]
2025-09-03 13:32:36,562 - ==> Total time: 0:01:10	 Eta: 0:04:43 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:38,186 - Train: 20.37% [1100/5400]  [20.4/100.0] [batch_t 0.056 (0.061)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.221 (0.228)]
2025-09-03 13:32:40,063 - ==> Total time: 0:01:14	 Eta: 0:04:40 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:41,477 - Train: 21.30% [1150/5400]  [21.3/100.0] [batch_t 0.055 (0.064)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.208 (0.222)]
2025-09-03 13:32:43,573 - ==> Total time: 0:01:18	 Eta: 0:04:36 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:44,739 - Train: 22.22% [1200/5400]  [22.2/100.0] [batch_t 0.055 (0.065)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.210 (0.214)]
2025-09-03 13:32:47,056 - ==> Total time: 0:01:21	 Eta: 0:04:32 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:47,952 - Train: 23.15% [1250/5400]  [23.1/100.0] [batch_t 0.056 (0.070)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.218 (0.213)]
2025-09-03 13:32:50,489 - ==> Total time: 0:01:24	 Eta: 0:04:28 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:51,135 - Train: 24.07% [1300/5400]  [24.1/100.0] [batch_t 0.057 (0.082)] [data_t 0.002] [optim_t 0.056] [lr 0.000050] [cos 0.214 (0.212)]
2025-09-03 13:32:53,896 - Train: 25.00% [1350/5400]  [25.0/100.0] [batch_t 0.055 (0.055)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.192 (0.207)]
2025-09-03 13:32:53,897 - ==> Total time: 0:01:28	 Eta: 0:04:24 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:32:57,128 - Train: 25.93% [1400/5400]  [25.9/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.190 (0.201)]
2025-09-03 13:32:57,349 - ==> Total time: 0:01:31	 Eta: 0:04:21 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:00,409 - Train: 26.85% [1450/5400]  [26.9/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.190 (0.195)]
2025-09-03 13:33:00,851 - ==> Total time: 0:01:35	 Eta: 0:04:17 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:03,680 - Train: 27.78% [1500/5400]  [27.8/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.191 (0.191)]
2025-09-03 13:33:04,342 - ==> Total time: 0:01:38	 Eta: 0:04:13 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:06,857 - Train: 28.70% [1550/5400]  [28.7/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.184 (0.188)]
2025-09-03 13:33:07,740 - ==> Total time: 0:01:42	 Eta: 0:04:10 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:10,172 - Train: 29.63% [1600/5400]  [29.6/100.0] [batch_t 0.056 (0.062)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.186 (0.187)]
2025-09-03 13:33:11,277 - ==> Total time: 0:01:45	 Eta: 0:04:06 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:13,380 - Train: 30.56% [1650/5400]  [30.6/100.0] [batch_t 0.055 (0.059)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.179 (0.183)]
2025-09-03 13:33:14,704 - ==> Total time: 0:01:49	 Eta: 0:04:02 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:16,678 - Train: 31.48% [1700/5400]  [31.5/100.0] [batch_t 0.056 (0.060)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.167 (0.180)]
2025-09-03 13:33:18,224 - ==> Total time: 0:01:52	 Eta: 0:03:59 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:19,939 - Train: 32.41% [1750/5400]  [32.4/100.0] [batch_t 0.055 (0.060)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.178 (0.177)]
2025-09-03 13:33:21,707 - ==> Total time: 0:01:56	 Eta: 0:03:55 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:23,196 - Train: 33.33% [1800/5400]  [33.3/100.0] [batch_t 0.055 (0.061)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.174 (0.176)]
2025-09-03 13:33:25,183 - ==> Total time: 0:01:59	 Eta: 0:03:52 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:26,420 - Train: 34.26% [1850/5400]  [34.3/100.0] [batch_t 0.055 (0.062)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.180 (0.174)]
2025-09-03 13:33:28,631 - ==> Total time: 0:02:03	 Eta: 0:03:48 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:29,634 - Train: 35.19% [1900/5400]  [35.2/100.0] [batch_t 0.055 (0.067)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.174 (0.170)]
2025-09-03 13:33:32,064 - ==> Total time: 0:02:06	 Eta: 0:03:44 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:32,824 - Train: 36.11% [1950/5400]  [36.1/100.0] [batch_t 0.056 (0.070)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.183 (0.171)]
2025-09-03 13:33:35,474 - ==> Total time: 0:02:09	 Eta: 0:03:41 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:36,021 - Train: 37.04% [2000/5400]  [37.0/100.0] [batch_t 0.058 (0.108)] [data_t 0.002] [optim_t 0.056] [lr 0.000050] [cos 0.161 (0.167)]
2025-09-03 13:33:38,789 - Train: 37.96% [2050/5400]  [38.0/100.0] [batch_t 0.055 (0.055)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.168 (0.167)]
2025-09-03 13:33:38,900 - ==> Total time: 0:02:13	 Eta: 0:03:37 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:41,999 - Train: 38.89% [2100/5400]  [38.9/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.178 (0.165)]
2025-09-03 13:33:42,331 - ==> Total time: 0:02:16	 Eta: 0:03:33 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:45,225 - Train: 39.81% [2150/5400]  [39.8/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.163 (0.163)]
2025-09-03 13:33:45,778 - ==> Total time: 0:02:20	 Eta: 0:03:30 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:48,493 - Train: 40.74% [2200/5400]  [40.7/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.164 (0.162)]
2025-09-03 13:33:49,267 - ==> Total time: 0:02:23	 Eta: 0:03:26 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:51,758 - Train: 41.67% [2250/5400]  [41.7/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.158 (0.161)]
2025-09-03 13:33:52,752 - ==> Total time: 0:02:27	 Eta: 0:03:23 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:55,045 - Train: 42.59% [2300/5400]  [42.6/100.0] [batch_t 0.055 (0.059)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.155 (0.158)]
2025-09-03 13:33:56,259 - ==> Total time: 0:02:30	 Eta: 0:03:19 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:33:58,217 - Train: 43.52% [2350/5400]  [43.5/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.165 (0.159)]
2025-09-03 13:33:59,653 - ==> Total time: 0:02:34	 Eta: 0:03:16 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:01,432 - Train: 44.44% [2400/5400]  [44.4/100.0] [batch_t 0.055 (0.060)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.157 (0.157)]
2025-09-03 13:34:03,090 - ==> Total time: 0:02:37	 Eta: 0:03:12 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:04,657 - Train: 45.37% [2450/5400]  [45.4/100.0] [batch_t 0.055 (0.061)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.141 (0.155)]
2025-09-03 13:34:06,535 - ==> Total time: 0:02:40	 Eta: 0:03:08 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:07,876 - Train: 46.30% [2500/5400]  [46.3/100.0] [batch_t 0.055 (0.061)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.142 (0.153)]
2025-09-03 13:34:09,976 - ==> Total time: 0:02:44	 Eta: 0:03:05 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:11,054 - Train: 47.22% [2550/5400]  [47.2/100.0] [batch_t 0.055 (0.061)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.148 (0.151)]
2025-09-03 13:34:13,374 - ==> Total time: 0:02:47	 Eta: 0:03:01 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:14,262 - Train: 48.15% [2600/5400]  [48.1/100.0] [batch_t 0.056 (0.069)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.150 (0.152)]
2025-09-03 13:34:16,804 - ==> Total time: 0:02:51	 Eta: 0:02:58 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:17,526 - Train: 49.07% [2650/5400]  [49.1/100.0] [batch_t 0.057 (0.084)] [data_t 0.002] [optim_t 0.055] [lr 0.000050] [cos 0.151 (0.152)]
2025-09-03 13:34:20,297 - Train: 50.00% [2700/5400]  [50.0/100.0] [batch_t 0.055 (0.055)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.157 (0.151)]
2025-09-03 13:34:20,298 - ==> Total time: 0:02:54	 Eta: 0:02:54 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:23,553 - Train: 50.93% [2750/5400]  [50.9/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.155 (0.150)]
2025-09-03 13:34:23,775 - ==> Total time: 0:02:58	 Eta: 0:02:51 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:26,921 - Train: 51.85% [2800/5400]  [51.9/100.0] [batch_t 0.055 (0.060)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.141 (0.150)]
2025-09-03 13:34:27,364 - ==> Total time: 0:03:01	 Eta: 0:02:47 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:30,170 - Train: 52.78% [2850/5400]  [52.8/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.150 (0.148)]
2025-09-03 13:34:30,834 - ==> Total time: 0:03:05	 Eta: 0:02:44 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:33,458 - Train: 53.70% [2900/5400]  [53.7/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.152 (0.148)]
2025-09-03 13:34:34,343 - ==> Total time: 0:03:08	 Eta: 0:02:40 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:36,725 - Train: 54.63% [2950/5400]  [54.6/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.148 (0.149)]
2025-09-03 13:34:37,829 - ==> Total time: 0:03:12	 Eta: 0:02:37 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:40,024 - Train: 55.56% [3000/5400]  [55.6/100.0] [batch_t 0.055 (0.059)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.144 (0.148)]
2025-09-03 13:34:41,351 - ==> Total time: 0:03:15	 Eta: 0:02:33 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:43,297 - Train: 56.48% [3050/5400]  [56.5/100.0] [batch_t 0.055 (0.060)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.155 (0.146)]
2025-09-03 13:34:44,844 - ==> Total time: 0:03:19	 Eta: 0:02:30 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:46,578 - Train: 57.41% [3100/5400]  [57.4/100.0] [batch_t 0.055 (0.060)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.149 (0.144)]
2025-09-03 13:34:48,346 - ==> Total time: 0:03:22	 Eta: 0:02:26 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:49,807 - Train: 58.33% [3150/5400]  [58.3/100.0] [batch_t 0.055 (0.063)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.143 (0.145)]
2025-09-03 13:34:51,797 - ==> Total time: 0:03:26	 Eta: 0:02:23 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:53,017 - Train: 59.26% [3200/5400]  [59.3/100.0] [batch_t 0.055 (0.063)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.139 (0.141)]
2025-09-03 13:34:55,227 - ==> Total time: 0:03:29	 Eta: 0:02:19 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:56,216 - Train: 60.19% [3250/5400]  [60.2/100.0] [batch_t 0.055 (0.064)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.150 (0.142)]
2025-09-03 13:34:58,648 - ==> Total time: 0:03:33	 Eta: 0:02:16 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:34:59,412 - Train: 61.11% [3300/5400]  [61.1/100.0] [batch_t 0.057 (0.073)] [data_t 0.002] [optim_t 0.055] [lr 0.000050] [cos 0.143 (0.141)]
2025-09-03 13:35:02,070 - ==> Total time: 0:03:36	 Eta: 0:02:12 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:02,609 - Train: 62.04% [3350/5400]  [62.0/100.0] [batch_t 0.058 (0.103)] [data_t 0.002] [optim_t 0.056] [lr 0.000050] [cos 0.137 (0.142)]
2025-09-03 13:35:05,384 - Train: 62.96% [3400/5400]  [63.0/100.0] [batch_t 0.055 (0.055)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.137 (0.142)]
2025-09-03 13:35:05,495 - ==> Total time: 0:03:39	 Eta: 0:02:09 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:08,602 - Train: 63.89% [3450/5400]  [63.9/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.141 (0.141)]
2025-09-03 13:35:08,934 - ==> Total time: 0:03:43	 Eta: 0:02:05 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:11,827 - Train: 64.81% [3500/5400]  [64.8/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.136 (0.141)]
2025-09-03 13:35:12,381 - ==> Total time: 0:03:46	 Eta: 0:02:02 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:15,055 - Train: 65.74% [3550/5400]  [65.7/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.140 (0.141)]
2025-09-03 13:35:15,829 - ==> Total time: 0:03:50	 Eta: 0:01:58 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:18,255 - Train: 66.67% [3600/5400]  [66.7/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.142 (0.140)]
2025-09-03 13:35:19,250 - ==> Total time: 0:03:53	 Eta: 0:01:55 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:21,475 - Train: 67.59% [3650/5400]  [67.6/100.0] [batch_t 0.055 (0.059)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.128 (0.140)]
2025-09-03 13:35:22,691 - ==> Total time: 0:03:57	 Eta: 0:01:51 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:24,713 - Train: 68.52% [3700/5400]  [68.5/100.0] [batch_t 0.055 (0.059)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.147 (0.140)]
2025-09-03 13:35:26,148 - ==> Total time: 0:04:00	 Eta: 0:01:48 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:27,954 - Train: 69.44% [3750/5400]  [69.4/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.150 (0.141)]
2025-09-03 13:35:29,612 - ==> Total time: 0:04:04	 Eta: 0:01:44 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:31,245 - Train: 70.37% [3800/5400]  [70.4/100.0] [batch_t 0.055 (0.061)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.137 (0.139)]
2025-09-03 13:35:33,125 - ==> Total time: 0:04:07	 Eta: 0:01:41 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:34,531 - Train: 71.30% [3850/5400]  [71.3/100.0] [batch_t 0.055 (0.062)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.139 (0.140)]
2025-09-03 13:35:36,631 - ==> Total time: 0:04:11	 Eta: 0:01:37 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:37,811 - Train: 72.22% [3900/5400]  [72.2/100.0] [batch_t 0.055 (0.065)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.127 (0.136)]
2025-09-03 13:35:40,243 - ==> Total time: 0:04:14	 Eta: 0:01:34 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:41,134 - Train: 73.15% [3950/5400]  [73.1/100.0] [batch_t 0.056 (0.069)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.146 (0.140)]
2025-09-03 13:35:43,675 - ==> Total time: 0:04:18	 Eta: 0:01:30 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:44,351 - Train: 74.07% [4000/5400]  [74.1/100.0] [batch_t 0.057 (0.082)] [data_t 0.002] [optim_t 0.056] [lr 0.000050] [cos 0.129 (0.133)]
2025-09-03 13:35:47,120 - Train: 75.00% [4050/5400]  [75.0/100.0] [batch_t 0.055 (0.055)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.147 (0.137)]
2025-09-03 13:35:47,121 - ==> Total time: 0:04:21	 Eta: 0:01:27 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:50,355 - Train: 75.93% [4100/5400]  [75.9/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.144 (0.136)]
2025-09-03 13:35:50,576 - ==> Total time: 0:04:25	 Eta: 0:01:23 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:53,549 - Train: 76.85% [4150/5400]  [76.9/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.054] [lr 0.000050] [cos 0.136 (0.135)]
2025-09-03 13:35:53,992 - ==> Total time: 0:04:28	 Eta: 0:01:20 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:56,751 - Train: 77.78% [4200/5400]  [77.8/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.143 (0.135)]
2025-09-03 13:35:57,414 - ==> Total time: 0:04:31	 Eta: 0:01:16 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:35:59,976 - Train: 78.70% [4250/5400]  [78.7/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.124 (0.134)]
2025-09-03 13:36:00,861 - ==> Total time: 0:04:35	 Eta: 0:01:13 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:03,193 - Train: 79.63% [4300/5400]  [79.6/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000050] [cos 0.140 (0.136)]
2025-09-03 13:36:04,298 - ==> Total time: 0:04:38	 Eta: 0:01:09 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:06,409 - Train: 80.56% [4350/5400]  [80.6/100.0] [batch_t 0.056 (0.059)] [data_t 0.002] [optim_t 0.054] [lr 0.000005] [cos 0.142 (0.134)]
2025-09-03 13:36:07,735 - ==> Total time: 0:04:42	 Eta: 0:01:06 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:09,677 - Train: 81.48% [4400/5400]  [81.5/100.0] [batch_t 0.055 (0.060)] [data_t 0.002] [optim_t 0.054] [lr 0.000005] [cos 0.123 (0.133)]
2025-09-03 13:36:11,223 - ==> Total time: 0:04:45	 Eta: 0:01:02 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:12,963 - Train: 82.41% [4450/5400]  [82.4/100.0] [batch_t 0.055 (0.061)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.134 (0.131)]
2025-09-03 13:36:14,730 - ==> Total time: 0:04:49	 Eta: 0:00:59 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:16,252 - Train: 83.33% [4500/5400]  [83.3/100.0] [batch_t 0.055 (0.061)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.130 (0.132)]
2025-09-03 13:36:18,240 - ==> Total time: 0:04:52	 Eta: 0:00:55 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:19,534 - Train: 84.26% [4550/5400]  [84.3/100.0] [batch_t 0.055 (0.063)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.126 (0.132)]
2025-09-03 13:36:21,743 - ==> Total time: 0:04:56	 Eta: 0:00:52 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:22,752 - Train: 85.19% [4600/5400]  [85.2/100.0] [batch_t 0.055 (0.066)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.137 (0.133)]
2025-09-03 13:36:25,185 - ==> Total time: 0:04:59	 Eta: 0:00:48 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:25,993 - Train: 86.11% [4650/5400]  [86.1/100.0] [batch_t 0.057 (0.067)] [data_t 0.002] [optim_t 0.056] [lr 0.000005] [cos 0.134 (0.135)]
2025-09-03 13:36:28,649 - ==> Total time: 0:05:03	 Eta: 0:00:45 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:29,263 - Train: 87.04% [4700/5400]  [87.0/100.0] [batch_t 0.058 (0.108)] [data_t 0.002] [optim_t 0.056] [lr 0.000005] [cos 0.142 (0.137)]
2025-09-03 13:36:32,041 - Train: 87.96% [4750/5400]  [88.0/100.0] [batch_t 0.055 (0.056)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.131 (0.132)]
2025-09-03 13:36:32,153 - ==> Total time: 0:05:06	 Eta: 0:00:41 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:35,326 - Train: 88.89% [4800/5400]  [88.9/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.133 (0.132)]
2025-09-03 13:36:35,658 - ==> Total time: 0:05:10	 Eta: 0:00:38 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:38,523 - Train: 89.81% [4850/5400]  [89.8/100.0] [batch_t 0.055 (0.057)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.127 (0.131)]
2025-09-03 13:36:39,076 - ==> Total time: 0:05:13	 Eta: 0:00:34 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:41,720 - Train: 90.74% [4900/5400]  [90.7/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.140 (0.132)]
2025-09-03 13:36:42,494 - ==> Total time: 0:05:16	 Eta: 0:00:31 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:44,927 - Train: 91.67% [4950/5400]  [91.7/100.0] [batch_t 0.055 (0.058)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.136 (0.132)]
2025-09-03 13:36:45,921 - ==> Total time: 0:05:20	 Eta: 0:00:27 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:48,140 - Train: 92.59% [5000/5400]  [92.6/100.0] [batch_t 0.055 (0.059)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.133 (0.130)]
2025-09-03 13:36:49,356 - ==> Total time: 0:05:23	 Eta: 0:00:24 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:51,366 - Train: 93.52% [5050/5400]  [93.5/100.0] [batch_t 0.055 (0.059)] [data_t 0.002] [optim_t 0.054] [lr 0.000005] [cos 0.140 (0.132)]
2025-09-03 13:36:52,803 - ==> Total time: 0:05:27	 Eta: 0:00:20 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:54,676 - Train: 94.44% [5100/5400]  [94.4/100.0] [batch_t 0.055 (0.064)] [data_t 0.002] [optim_t 0.054] [lr 0.000005] [cos 0.119 (0.130)]
2025-09-03 13:36:56,331 - ==> Total time: 0:05:30	 Eta: 0:00:17 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:36:57,879 - Train: 95.37% [5150/5400]  [95.4/100.0] [batch_t 0.055 (0.060)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.141 (0.131)]
2025-09-03 13:36:59,757 - ==> Total time: 0:05:34	 Eta: 0:00:13 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:37:01,100 - Train: 96.30% [5200/5400]  [96.3/100.0] [batch_t 0.055 (0.061)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.140 (0.130)]
2025-09-03 13:37:03,199 - ==> Total time: 0:05:37	 Eta: 0:00:10 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:37:04,349 - Train: 97.22% [5250/5400]  [97.2/100.0] [batch_t 0.055 (0.062)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.118 (0.131)]
2025-09-03 13:37:06,669 - ==> Total time: 0:05:41	 Eta: 0:00:06 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:37:07,603 - Train: 98.15% [5300/5400]  [98.1/100.0] [batch_t 0.056 (0.070)] [data_t 0.002] [optim_t 0.054] [lr 0.000005] [cos 0.135 (0.132)]
2025-09-03 13:37:10,142 - ==> Total time: 0:05:44	 Eta: 0:00:03 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:37:10,840 - Train: 99.07% [5350/5400]  [99.1/100.0] [batch_t 0.057 (0.083)] [data_t 0.002] [optim_t 0.056] [lr 0.000005] [cos 0.137 (0.136)]
2025-09-03 13:37:13,604 - Train: 100.00% [5400/5400]  [100.0/100.0] [batch_t 0.055 (0.055)] [data_t 0.002] [optim_t 0.053] [lr 0.000005] [cos 0.129 (0.130)]
2025-09-03 13:37:17,094 - Test: 25.51% [50/196] [batch_t 0.063 (0.067)] [cos 0.202 (0.201)]
2025-09-03 13:37:20,311 - Test: 51.02% [100/196] [batch_t 0.063 (0.066)] [cos 0.202 (0.198)]
2025-09-03 13:37:23,515 - Test: 76.53% [150/196] [batch_t 0.063 (0.065)] [cos 0.123 (0.194)]
2025-09-03 13:37:26,652 - Test: 100.00% [196/196] [batch_t 0.290 (0.066)] [cos 0.160 (0.181)]
2025-09-03 13:38:02,787 - ==> Metric Time for wooden_beads   :   0.000 (S_AUROC)	  0.000 (S_AUPR)	  0.002 (mAUROC_sp_max)	  0.001 (mAP_sp_max)	  0.001 (mF1_max_sp_max)	  0.000 (mAUROC_px)	  0.000 (mAP_px)	  9.487 (mF1_max_px)	  0.000 (mAUPRO_px)	  9.452 (mIoU_max_px)	
2025-09-03 13:38:02,818 - 
|     Name     |  S_AUROC  |   S_AUROC (Max)    |  S_AUPR  |    S_AUPR (Max)    |  mAUROC_sp_max  |  mAUROC_sp_max (Max)  |  mAP_sp_max  |  mAP_sp_max (Max)  |  mF1_max_sp_max  |  mF1_max_sp_max (Max)  |  mAUROC_px  |  mAUROC_px (Max)   |  mAP_px  |    mAP_px (Max)    |  mF1_max_px  |  mF1_max_px (Max)  |  mAUPRO_px  |  mAUPRO_px (Max)   |  mIoU_max_px  |  mIoU_max_px (Max)  |
|:------------:|:---------:|:------------------:|:--------:|:------------------:|:---------------:|:---------------------:|:------------:|:------------------:|:----------------:|:----------------------:|:-----------:|:------------------:|:--------:|:------------------:|:------------:|:------------------:|:-----------:|:------------------:|:-------------:|:-------------------:|
| wooden_beads |  87.814   | 87.814 (100 epoch) |  94.955  | 94.955 (100 epoch) |     82.812      |  82.812 (100 epoch)   |    79.800    | 79.800 (100 epoch) |      72.111      |   72.111 (100 epoch)   |   96.235    | 96.235 (100 epoch) |  14.980  | 14.980 (100 epoch) |    21.482    | 21.482 (100 epoch) |   81.811    | 81.811 (100 epoch) |    12.034     | 12.034 (100 epoch)  |
2025-09-03 13:38:02,850 - ==> Total time: 0:06:37	 Eta: 0:00:00 	Logged in 'runs/single_cls/rdepipolar_256_100e/wooden_beads/RDEpipolarTrainer_configs_z_realiad_subsample_rdepipolar_256_100e_20250903-133125'
2025-09-03 13:38:03,207 - finish training
