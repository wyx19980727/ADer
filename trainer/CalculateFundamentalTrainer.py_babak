from . import TRAINER
from ._base_trainer import BaseTrainer
import numpy as np
import torch
import cv2 as cv

def calculate_fundamental_matrix(img1_path, img2_path):
    try:
        img1 = cv.imread(img1_path, cv.IMREAD_GRAYSCALE)
        img2 = cv.imread(img2_path, cv.IMREAD_GRAYSCALE)
        sift = cv.SIFT_create()
        # find the keypoints and descriptors with SIFT
        kp1, des1 = sift.detectAndCompute(img1, None)
        kp2, des2 = sift.detectAndCompute(img2, None)
        # FLANN parameters
        # FLANN parameters
        FLANN_INDEX_KDTREE = 1
        index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)
        search_params = dict(checks=50)
        flann = cv.FlannBasedMatcher(index_params, search_params)
        matches = flann.knnMatch(des1, des2, k=2)
        good = []
        pts1 = []
        pts2 = []
        # ratio test as per Lowe's paper
        for i, (m, n) in enumerate(matches):
            if m.distance < 0.8 * n.distance:
                good.append(m)
                pts2.append(kp2[m.trainIdx].pt)
                pts1.append(kp1[m.queryIdx].pt)
        pts1 = np.int32(pts1)
        pts2 = np.int32(pts2)
        #import ipdb; ipdb.set_trace()
        if len(pts1) < 8 or len(pts2) < 8:
            Fundamental_matrix = None
        else:
            Fundamental_matrix, mask = cv.findFundamentalMat(pts1, pts2, cv.USAC_MAGSAC)

        if Fundamental_matrix is not None and Fundamental_matrix.shape != (3, 3):
            import ipdb; ipdb.set_trace()
        return Fundamental_matrix
    except:
        Fundamental_matrix = None
        return Fundamental_matrix



@TRAINER.register_module
class CalculateFundamentalTrainer(BaseTrainer):
    def __init__(self, cfg):
        super(CalculateFundamentalTrainer, self).__init__(cfg)
        
    def set_input(self, inputs):
        # self.imgs = inputs['img'].cuda()
        # self.imgs_mask = inputs['img_mask'].cuda()
        # self.cls_name = inputs['cls_name']
        # self.anomaly = inputs['anomaly']
        # self.bs = self.imgs.shape[0]
        # import ipdb; ipdb.set_trace()
        self.imgs = inputs['img'].cuda()
        self.imgs_mask = inputs['img_mask'].cuda()
        if len(self.imgs_mask.shape)==5:
            # self.imgs = self.imgs.flatten(0, 1)
            self.imgs_mask = self.imgs_mask.flatten(0, 1)
        self.cls_name = inputs['cls_name']
        self.cls_name = np.array(self.cls_name)
        self.cls_name = np.transpose(self.cls_name, (1, 0)) 
        #class_to_index = {cls: idx for idx, cls in enumerate(real_iad_classes)}
        #import ipdb; ipdb.set_trace()
        #self.contrast_labels = np.tile(np.arange(self.cls_name.shape[1]), (self.cls_name.shape[0], 1)).flatten()
        #self.contrast_labels = np.array([class_to_index[item] for item in self.cls_name.flatten()])
        
        self.anomaly = inputs['anomaly']
        self.img_path = inputs['img_path']
        #import ipdb; ipdb.set_trace()
        self.img_path = np.array(self.img_path)
        self.img_path = np.transpose(self.img_path, (1, 0))
        # self.img_path = self.img_path.flatten()
  
        self.sample_anomaly = inputs['sample_anomaly']
        self.bs = self.imgs.shape[0]
        #import ipdb; ipdb.set_trace()
        num_views = 5
        class_indices = torch.arange(0, num_views) # exclude top-view
        index_combinations = torch.cartesian_prod(class_indices, class_indices) # Generate all possible pairs (including self-pairs and ordered pairs)
        mask = index_combinations[:, 0] != index_combinations[:, 1] # Create a mask to filter out pairs where i == j
        self.index_combinations = index_combinations[mask]
        
    def train(self):
        Fundamental_Matrix_Result = dict()
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        for i, train_data in enumerate(self.train_loader):
            self.set_input(train_data)
            for sample_path in self.img_path:
                for index_pair in self.index_combinations:
                    i, j = index_pair
                    img_i_path = sample_path[i]
                    img_j_path = sample_path[j]
                    img_i_name = img_i_path.split('/')[-1]
                    img_j_name = img_j_path.split('/')[-1]
                    
                    Fundamental_matrix = calculate_fundamental_matrix(img_i_path, img_j_path)
            
                    if Fundamental_matrix is not None:
                        Fundamental_matrix = torch.tensor(Fundamental_matrix, dtype=torch.float32, device=device)
                        Fundamental_Matrix_Result[img_i_name+"_and_"+img_j_name] = Fundamental_matrix
                    else:
                        Fundamental_Matrix_Result[img_i_name+"_and_"+img_j_name] = None
                        
        for i, test_data in enumerate(self.test_loader):
            self.set_input(test_data)
            for sample_path in self.img_path:
                for index_pair in self.index_combinations:
                    i, j = index_pair
                    img_i_path = sample_path[i]
                    img_j_path = sample_path[j]
                    img_i_name = img_i_path.split('/')[-1]
                    img_j_name = img_j_path.split('/')[-1]
                    
                    Fundamental_matrix = calculate_fundamental_matrix(img_i_path, img_j_path)
            
                    if Fundamental_matrix is not None:
                        Fundamental_matrix = torch.tensor(Fundamental_matrix, dtype=torch.float32, device=device)
                        Fundamental_Matrix_Result[img_i_name+"_and_"+img_j_name] = Fundamental_matrix
                    else:
                        Fundamental_Matrix_Result[img_i_name+"_and_"+img_j_name] = None
        
        # Save the results to a file
        torch.save(Fundamental_Matrix_Result, './CV2_USAC_MAGSAC_fundamental_matrix_results.pth')